{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebd70769-d210-435a-9e43-572094a17f41",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Tensaurus\n",
    "\n",
    "This notebook reproduces the salient characteristics of the [Tensaurus](https://ieeexplore.ieee.org/document/9065579) accelerator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3167230-621f-4588-aa60-1699e4945aa6",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Import the necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e3c247-e1ec-4ff6-83cf-8294994426ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HiFiber boilerplate\n",
    "\n",
    "from fibertree_bootstrap import *\n",
    "\n",
    "fibertree_bootstrap(style=\"tree\", animation='movie')\n",
    "\n",
    "# Compilation boilerplate\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "from src import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08504df-be99-49b8-b5fc-3772d51a60f2",
   "metadata": {},
   "source": [
    "## Slice Partitioning Technique\n",
    "The uniform slice partitioning technique is described in section 4: SPARSE FORMATS of the Tensaurus paper. In the section, the authors described the compressed interleaved sparse slice (CISS) storage format, which implements uniform slice partitioning to achieve a higher memory bandwidth compared to existing sparse tensor storage formats, including compressed sparse row (CSR), compressed sparse fiber (CSF), co-ordinate (COO), and their variants.\n",
    "\n",
    "To model the storage format and partitioning technique, the `uniform_slice` function is introduced. The implementation details of the function is given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fda3ff-6481-4fc1-b5a2-30ba5afc21a8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "I = 5\n",
    "J = 5\n",
    "K = 2\n",
    "\n",
    "density = [1, 0.8, 0.5]\n",
    "seed = 5\n",
    "\n",
    "A_IJK = Tensor.fromRandom(rank_ids=[\"I\", \"J\", \"K\"], shape=[I, J, K], seed=seed, density=density, name=\"A\") # A tensor is created for visualization\n",
    "\n",
    "print(\"The fibertree for A_IJK before performing uniform slice partitioning:\")\n",
    "displayTensor(A_IJK)\n",
    "print(\"\\n\")\n",
    "\n",
    "def total_nnz(A):\n",
    "    \"\"\"\n",
    "    Returns the total non-zero value under each slice of the tensor A.\n",
    "    \"\"\"\n",
    "    res = dict()\n",
    "    a_i = A.getRoot()\n",
    "    for i, a_j in a_i:\n",
    "        res[i] = a_j.countValues()\n",
    "    return res\n",
    "\n",
    "\n",
    "def uniform_slice(self, numOfSlice):\n",
    "    \"\"\"\n",
    "    Takes a 3-tensor, self, and partitions it based on the number of slices, numOfSlice, specified by the user.\n",
    "    The function returns the partitioned version of the tensor.\n",
    "    \"\"\"\n",
    "    nnz = total_nnz(self)\n",
    "    track = [0 for i in range(numOfSlice)]\n",
    "    Z = Tensor(rank_ids=([self.getRankIds()[0] + '1', self.getRankIds()[0] + '0']  + self.getRankIds()[1:]))\n",
    "    Z.setName(self.getName())\n",
    "    z_i1 = Z.getRoot()\n",
    "    self_i = self.getRoot()\n",
    "    for i, self_j in self_i:\n",
    "        currSlice = track.index(min(track))\n",
    "        z_j = z_i1.getPayloadRef(currSlice).getPayloadRef(i)\n",
    "        z_j <<= self_j # Adds self_j subtree under a specific element in I0 of the output tensor\n",
    "        track[currSlice] += nnz[i]\n",
    "    return Z\n",
    "\n",
    "Tensor.uniform_slice = uniform_slice # The uniform_slice method is added to the Tensor class\n",
    "\n",
    "A_I1I0JK = A_IJK.uniform_slice(3)\n",
    "print(\"The fibertree A_I1I0JK after performing uniform slice partitioning:\")\n",
    "displayTensor(A_I1I0JK)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56edf0c-4bf8-4032-9f05-ebbcd291a7a1",
   "metadata": {},
   "source": [
    "## Kernel: DMTTKRP and SpMTTKRP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6318fb-9b00-4401-9d88-a3195d8f8ed4",
   "metadata": {},
   "source": [
    "### Initialization\n",
    "\n",
    "Initialize the input tensors. Tensor shapes and densities can be modified below.\n",
    "\n",
    "**Warning:** Large tensors will overwhelm the video generation. Either:\n",
    "1. Use small tensors; as a rule of thumb, fewer than 60 computes (e.g., multiplications) should be required.\n",
    "2. Do not generate a video; remove the `spacetime` specification from the `mapping` before compiling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5902c5c4-d6bd-4c7b-bfd3-d90f47e7809b",
   "metadata": {},
   "outputs": [],
   "source": [
    "I = 4\n",
    "J = 2\n",
    "K = 2\n",
    "F = 2\n",
    "\n",
    "density = [0.8, 0.8, 0.9]\n",
    "seed = 0\n",
    "\n",
    "A_IJK = Tensor.fromRandom(rank_ids=[\"I\", \"J\", \"K\"], shape=[I, J, K], seed=seed, density=density, name=\"A\")\n",
    "B_JF = Tensor.fromRandom(rank_ids=[\"J\", \"F\"], shape=[J, F], seed=seed, density=[1, 1], name=\"B\")\n",
    "C_KF = Tensor.fromRandom(rank_ids=[\"K\", \"F\"], shape=[K, F], seed=seed + 1, density=[1, 1], name=\"C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdd255e-7f30-472a-9875-a55c612148bf",
   "metadata": {},
   "source": [
    "Execute the following cell if you wish to visualize tensor `A_IJK`, `B_JF`, and `C_KF`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d036a6-7386-4b7a-9bba-c36ba7c54d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "displayTensor(A_IJK)\n",
    "displayTensor(B_JF)\n",
    "displayTensor(C_KF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd5a783-6cf3-4d9f-a203-a65f28aac3bd",
   "metadata": {},
   "source": [
    "### Compile from TeAAL Specification and Run\n",
    "\n",
    "Below is the TeAAL specification for MTTKRP on Tensaurus. To simulate the accelerator:\n",
    "1. Compile it to HiFiber by running the cell, inserting a new cell\n",
    "2. Run the new cell, which will\n",
    "    - Execute the kernel\n",
    "    - Generate visualizations of the actions of the kernel\n",
    "\n",
    "Remember, if you are using large tensors, remove the spacetime specification to generate a kernel that does not produce videos. Outputs can still be checked below.\n",
    "\n",
    "#### Notes\n",
    "\n",
    "- Small tensors are required for video generation. If you are using large tensors, remove the spacetime specification to generate a kernel that does not produce videos. Outputs can still be checked below.\n",
    "- The visualizations generated by TeAAL do not account for Tensaurus's partitioning technique and sparse tensor storage format. A modified HiFiber visualization that implements uniform slice partitioning is provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b26532-ac11-4137-acf4-44dea11d568f",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml = \"\"\"\n",
    "einsum:\n",
    "    declaration:\n",
    "        A: [I, J, K]\n",
    "        B: [J, F]\n",
    "        C: [K, F]\n",
    "        T: [I, J, F]\n",
    "        Y: [I, F]\n",
    "    expressions:\n",
    "        - T[i, j, f] = A[i, j, k] * C[k, f]\n",
    "        - Y[i, f] = T[i, j, f] * B[j, f]\n",
    "mapping:\n",
    "    rank-order:\n",
    "        A: [I, J, K]\n",
    "        B: [J, F]\n",
    "        C: [K, F]\n",
    "        T: [I, J, F]\n",
    "        Y: [I, F]\n",
    "    partitioning:\n",
    "        T:\n",
    "            I: [uniform_shape(8)]\n",
    "            J: [uniform_shape(8)]\n",
    "            K: [uniform_shape(8)]\n",
    "            F: [uniform_shape(32), uniform_shape(4)]\n",
    "        Y:\n",
    "            I: [uniform_shape(8)]\n",
    "            J: [uniform_shape(8)]\n",
    "            F: [uniform_shape(32), uniform_shape(4)]\n",
    "    loop-order:\n",
    "        T: [I1, I0, F2, J1, K1, J0, K0, F1, F0]\n",
    "        Y: [I1, I0, F2, J1, J0, F1, F0]\n",
    "    spacetime:\n",
    "        T:\n",
    "            space: [I1, F1, F0]\n",
    "            time: [I0, F2, J1, K1, J0, K0]\n",
    "        Y:\n",
    "            space: [I1, F1, F0]\n",
    "            time: [ I0, F2, J1, J0]\n",
    "\"\"\"\n",
    "\n",
    "utils.compile(yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23400b27-d2f7-42f5-a617-e957f1960be1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Visualize Uniform Slice Partitioning\n",
    "\n",
    "Tensaurus uses the compressed interleaved sparse slice (CISS) storage format to achieve a higher memory bandwidth. Since the CISS format implements uniform slice partitioning, the HiFiber loop nest below accounts for this partitioning  technique. Note that the *only* difference between the code generated by the above TeAAL specification and the below HiFiber code is the replacement of `splitUniform(8, depth=0)` with `uniform_slice(8)` for tensor `A` and `T` when partitioning rank `I`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b7b175-7a8c-4911-8796-8a746cdd33f4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "T_I1I0F2J1J0F1F0 = Tensor(rank_ids=[\"I1\", \"I0\", \"F2\", \"J1\", \"J0\", \"F1\", \"F0\"], name=\"T\")\n",
    "tmp0 = A_IJK\n",
    "tmp1 = tmp0.uniform_slice(8)\n",
    "A_I1I0JK = tmp1\n",
    "A_I1I0JK.setRankIds(rank_ids=[\"I1\", \"I0\", \"J\", \"K\"])\n",
    "tmp2 = A_I1I0JK\n",
    "tmp3 = tmp2.splitUniform(8, depth=3)\n",
    "A_I1I0JK1K0 = tmp3\n",
    "A_I1I0JK1K0.setRankIds(rank_ids=[\"I1\", \"I0\", \"J\", \"K1\", \"K0\"])\n",
    "tmp4 = A_I1I0JK1K0\n",
    "tmp5 = tmp4.splitUniform(8, depth=2)\n",
    "A_I1I0J1J0K1K0 = tmp5\n",
    "A_I1I0J1J0K1K0.setRankIds(rank_ids=[\"I1\", \"I0\", \"J1\", \"J0\", \"K1\", \"K0\"])\n",
    "tmp6 = C_KF\n",
    "tmp7 = tmp6.splitUniform(8, depth=0)\n",
    "C_K1K0F = tmp7\n",
    "C_K1K0F.setRankIds(rank_ids=[\"K1\", \"K0\", \"F\"])\n",
    "tmp8 = C_K1K0F\n",
    "tmp9 = tmp8.splitUniform(32, depth=2)\n",
    "tmp10 = tmp9.splitUniform(4, depth=3)\n",
    "C_K1K0F2F1F0 = tmp10\n",
    "C_K1K0F2F1F0.setRankIds(rank_ids=[\"K1\", \"K0\", \"F2\", \"F1\", \"F0\"])\n",
    "t_i1 = T_I1I0F2J1J0F1F0.getRoot()\n",
    "A_I1I0J1K1J0K0 = A_I1I0J1J0K1K0.swizzleRanks(rank_ids=[\"I1\", \"I0\", \"J1\", \"K1\", \"J0\", \"K0\"])\n",
    "C_F2K1K0F1F0 = C_K1K0F2F1F0.swizzleRanks(rank_ids=[\"F2\", \"K1\", \"K0\", \"F1\", \"F0\"])\n",
    "a_i1 = A_I1I0J1K1J0K0.getRoot()\n",
    "c_f2 = C_F2K1K0F1F0.getRoot()\n",
    "canvas = createCanvas(A_I1I0J1K1J0K0, C_F2K1K0F1F0, T_I1I0F2J1J0F1F0)\n",
    "for i1_pos, (i1, (t_i0, a_i0)) in enumerate(t_i1 << a_i1):\n",
    "    for i0_pos, (i0, (t_f2, a_j1)) in enumerate(t_i0 << a_i0):\n",
    "        for f2_pos, (f2, (t_j1, c_k1)) in enumerate(t_f2 << c_f2):\n",
    "            for j1_pos, (j1, (t_j0, a_k1)) in enumerate(t_j1 << a_j1):\n",
    "                for k1_pos, (k1, (a_j0, c_k0)) in enumerate(a_k1 & c_k1):\n",
    "                    for j0_pos, (j0, (t_f1, a_k0)) in enumerate(t_j0 << a_j0):\n",
    "                        for k0_pos, (k0, (a_val, c_f1)) in enumerate(a_k0 & c_k0):\n",
    "                            for f1_pos, (f1, (t_f0, c_f0)) in enumerate(t_f1 << c_f1):\n",
    "                                for f0_pos, (f0, (t_ref, c_val)) in enumerate(t_f0 << c_f0):\n",
    "                                    t_ref += a_val * c_val\n",
    "                                    canvas.addActivity((i1, i0, j1, k1, j0, k0), (f2, k1, k0, f1, f0), (i1, i0, f2, j1, j0, f1, f0), spacetime=((i1_pos, f1_pos, f0_pos), (i0_pos, f2_pos, j1_pos, k1_pos, j0_pos, k0_pos)))\n",
    "tmp11 = T_I1I0F2J1J0F1F0\n",
    "tmp12 = tmp11.swizzleRanks(rank_ids=[\"I1\", \"I0\", \"J1\", \"J0\", \"F2\", \"F1\", \"F0\"])\n",
    "tmp13 = tmp12.mergeRanks(depth=4, levels=2, coord_style=\"absolute\")\n",
    "tmp14 = tmp13.mergeRanks(depth=2, levels=1, coord_style=\"absolute\")\n",
    "tmp15 = tmp14.mergeRanks(depth=0, levels=1, coord_style=\"absolute\")\n",
    "tmp15.setRankIds(rank_ids=[\"I\", \"J\", \"F\"])\n",
    "T_IJF = tmp15\n",
    "displayCanvas(canvas)\n",
    "Y_I1I0F2F1F0 = Tensor(rank_ids=[\"I1\", \"I0\", \"F2\", \"F1\", \"F0\"], name=\"Y\")\n",
    "tmp16 = T_IJF\n",
    "tmp17 = tmp16.uniform_slice(8)\n",
    "T_I1I0JF = tmp17\n",
    "T_I1I0JF.setRankIds(rank_ids=[\"I1\", \"I0\", \"J\", \"F\"])\n",
    "tmp18 = T_I1I0JF\n",
    "tmp19 = tmp18.splitUniform(8, depth=2)\n",
    "T_I1I0J1J0F = tmp19\n",
    "T_I1I0J1J0F.setRankIds(rank_ids=[\"I1\", \"I0\", \"J1\", \"J0\", \"F\"])\n",
    "tmp20 = T_I1I0J1J0F\n",
    "tmp21 = tmp20.splitUniform(32, depth=4)\n",
    "tmp22 = tmp21.splitUniform(4, depth=5)\n",
    "T_I1I0J1J0F2F1F0 = tmp22\n",
    "T_I1I0J1J0F2F1F0.setRankIds(rank_ids=[\"I1\", \"I0\", \"J1\", \"J0\", \"F2\", \"F1\", \"F0\"])\n",
    "tmp23 = B_JF\n",
    "tmp24 = tmp23.splitUniform(8, depth=0)\n",
    "B_J1J0F = tmp24\n",
    "B_J1J0F.setRankIds(rank_ids=[\"J1\", \"J0\", \"F\"])\n",
    "tmp25 = B_J1J0F\n",
    "tmp26 = tmp25.splitUniform(32, depth=2)\n",
    "tmp27 = tmp26.splitUniform(4, depth=3)\n",
    "B_J1J0F2F1F0 = tmp27\n",
    "B_J1J0F2F1F0.setRankIds(rank_ids=[\"J1\", \"J0\", \"F2\", \"F1\", \"F0\"])\n",
    "y_i1 = Y_I1I0F2F1F0.getRoot()\n",
    "T_I1I0F2J1J0F1F0 = T_I1I0J1J0F2F1F0.swizzleRanks(rank_ids=[\"I1\", \"I0\", \"F2\", \"J1\", \"J0\", \"F1\", \"F0\"])\n",
    "B_F2J1J0F1F0 = B_J1J0F2F1F0.swizzleRanks(rank_ids=[\"F2\", \"J1\", \"J0\", \"F1\", \"F0\"])\n",
    "t_i1 = T_I1I0F2J1J0F1F0.getRoot()\n",
    "b_f2 = B_F2J1J0F1F0.getRoot()\n",
    "canvas = createCanvas(T_I1I0F2J1J0F1F0, B_F2J1J0F1F0, Y_I1I0F2F1F0)\n",
    "for i1_pos, (i1, (y_i0, t_i0)) in enumerate(y_i1 << t_i1):\n",
    "    for i0_pos, (i0, (y_f2, t_f2)) in enumerate(y_i0 << t_i0):\n",
    "        for f2_pos, (f2, (y_f1, (t_j1, b_j1))) in enumerate(y_f2 << (t_f2 & b_f2)):\n",
    "            for j1_pos, (j1, (t_j0, b_j0)) in enumerate(t_j1 & b_j1):\n",
    "                for j0_pos, (j0, (t_f1, b_f1)) in enumerate(t_j0 & b_j0):\n",
    "                    for f1_pos, (f1, (y_f0, (t_f0, b_f0))) in enumerate(y_f1 << (t_f1 & b_f1)):\n",
    "                        for f0_pos, (f0, (y_ref, (t_val, b_val))) in enumerate(y_f0 << (t_f0 & b_f0)):\n",
    "                            y_ref += t_val * b_val\n",
    "                            canvas.addActivity((i1, i0, f2, j1, j0, f1, f0), (f2, j1, j0, f1, f0), (i1, i0, f2, f1, f0), spacetime=((i1_pos, f1_pos, f0_pos), (i0_pos, f2_pos, j1_pos, j0_pos)))\n",
    "tmp28 = Y_I1I0F2F1F0\n",
    "tmp29 = tmp28.mergeRanks(depth=2, levels=2, coord_style=\"absolute\")\n",
    "tmp30 = tmp29.mergeRanks(depth=0, levels=1, coord_style=\"absolute\")\n",
    "tmp30.setRankIds(rank_ids=[\"I\", \"F\"])\n",
    "Y_IF = tmp30\n",
    "displayCanvas(canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98718fcc-9b45-4733-88f0-47cebc46ab04",
   "metadata": {},
   "source": [
    "### Check Results\n",
    "\n",
    "Check that above code (generated or provided) computes the correct result.\n",
    "\n",
    "**Note**: Should be used after executing the HiFiber loopnest (one of the above cells)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc64ffef-fbd3-4a67-a61f-02fc7043cc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.check_MTTKRP(A_IJK, B_JF, C_KF, Y_IF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6d3eab-e18e-4997-8b20-443639313588",
   "metadata": {},
   "source": [
    "## Kernel: DTTMc and SpTTMc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96af0ba8-e082-4dee-95d9-9862d8a5b293",
   "metadata": {},
   "source": [
    "### Initialization\n",
    "\n",
    "Initialize the input tensors. Tensor shapes and densities can be modified below.\n",
    "\n",
    "**Warning:** Large tensors will overwhelm the video generation. Either:\n",
    "1. Use small tensors; as a rule of thumb, fewer than 60 computes (e.g., multiplications) should be required.\n",
    "2. Do not generate a video; remove the `spacetime` specification from the `mapping` before compiling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90754c46-c653-4136-8474-7090fbb918d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "I = 4\n",
    "J = 2\n",
    "K = 2\n",
    "V = 2\n",
    "U = 2\n",
    "\n",
    "density = [0.8, 0.8, 0.9]\n",
    "seed = 0\n",
    "\n",
    "A_IJK = Tensor.fromRandom(rank_ids=[\"I\", \"J\", \"K\"], shape=[I, J, K], seed=seed, density=density, name=\"A\")\n",
    "B_JV = Tensor.fromRandom(rank_ids=[\"J\", \"V\"], shape=[J, V], seed=seed, density=[1, 1], name=\"B\")\n",
    "C_KU = Tensor.fromRandom(rank_ids=[\"K\", \"U\"], shape=[K, U], seed=seed + 1, density=[1, 1], name=\"C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ee4458-de90-4a62-a4b5-f9b2f8d1d421",
   "metadata": {},
   "source": [
    "Execute the following cell if you wish to visualize tensor `A_IJK`, `B_JV`, and `C_KU`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f3e381-8f10-44f5-98ce-82898a937939",
   "metadata": {},
   "outputs": [],
   "source": [
    "displayTensor(A_IJK)\n",
    "displayTensor(B_JV)\n",
    "displayTensor(C_KU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75eedb44-05aa-4e6a-bdb4-16f467fe3e75",
   "metadata": {},
   "source": [
    "### Compile from TeAAL Specification and Run\n",
    "\n",
    "Below is the TeAAL specification for TTMc on Tensaurus. To simulate the accelerator:\n",
    "1. Compile it to HiFiber by running the cell, inserting a new cell\n",
    "2. Run the new cell, which will\n",
    "    - Execute the kernel\n",
    "    - Generate visualizations of the actions of the kernel\n",
    "\n",
    "Remember, if you are using large tensors, remove the spacetime specification to generate a kernel that does not produce videos. Outputs can still be checked below.\n",
    "\n",
    "#### Notes\n",
    "\n",
    "- Small tensors are required for video generation. If you are using large tensors, remove the spacetime specification to generate a kernel that does not produce videos. Outputs can still be checked below.\n",
    "- The visualizations generated by TeAAL do not account for Tensaurus's partitioning technique and sparse tensor storage format. A modified HiFiber visualization that implements uniform slice partitioning is provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa601d7-16a4-4c37-8081-1b0c3d8b00b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml = \"\"\"\n",
    "einsum:\n",
    "    declaration:\n",
    "        A: [I, J, K]\n",
    "        B: [J, V]\n",
    "        C: [K, U]\n",
    "        T: [I, J, U]\n",
    "        Y: [I, V, U]\n",
    "    expressions:\n",
    "        - T[i, j, u] = A[i, j, k] * C[k, u]\n",
    "        - Y[i, v, u] = T[i, j, u] * B[j, v]\n",
    "mapping:\n",
    "    rank-order:\n",
    "        A: [I, J, K]\n",
    "        B: [J, V]\n",
    "        C: [K, U]\n",
    "        T: [I, J, U]\n",
    "        Y: [I, V, U]\n",
    "    partitioning:\n",
    "        T: \n",
    "            I: [uniform_shape(8)]\n",
    "            K: [uniform_shape(8)]\n",
    "            U: [uniform_shape(32), uniform_shape(4)]\n",
    "        Y:\n",
    "            I: [uniform_shape(8)]\n",
    "            U: [uniform_shape(32), uniform_shape(4)]\n",
    "            V: [uniform_shape(8)]\n",
    "    loop-order:\n",
    "        T: [I1, I0, J, U2, K1, K0, U1, U0]\n",
    "        Y: [I1, I0, J, V1, U2, V0, U1, U0]\n",
    "    spacetime:\n",
    "        T:\n",
    "            space: [I1, U1, U0]\n",
    "            time: [I0, J, U2, K1, K0]\n",
    "        Y:\n",
    "            space: [I1, U1, U0]\n",
    "            time: [I0, J, V1, U2, V0]\n",
    "\"\"\"\n",
    "\n",
    "utils.compile(yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048b09e7-e140-46ff-a577-0cfc921d816c",
   "metadata": {},
   "source": [
    "### Visualize Uniform Slice Partitioning\n",
    "\n",
    "Tensaurus uses the compressed interleaved sparse slice (CISS) storage format to achieve a higher memory bandwidth. Since the CISS format implements uniform slice partitioning, the HiFiber loop nest below accounts for this partitioning  technique. Note that the *only* difference between the code generated by the above TeAAL specification and the below HiFiber code is the replacement of `splitUniform(8, depth=0)` with `uniform_slice(8)` for tensor `A` and `T` when partitioning rank `I`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480621f2-6393-4d4c-a0d1-fd3e8cec185e",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_I1I0JU2U1U0 = Tensor(rank_ids=[\"I1\", \"I0\", \"J\", \"U2\", \"U1\", \"U0\"], name=\"T\")\n",
    "tmp0 = A_IJK\n",
    "tmp1 = tmp0.uniform_slice(8)\n",
    "A_I1I0JK = tmp1\n",
    "A_I1I0JK.setRankIds(rank_ids=[\"I1\", \"I0\", \"J\", \"K\"])\n",
    "tmp2 = A_I1I0JK\n",
    "tmp3 = tmp2.splitUniform(8, depth=3)\n",
    "A_I1I0JK1K0 = tmp3\n",
    "A_I1I0JK1K0.setRankIds(rank_ids=[\"I1\", \"I0\", \"J\", \"K1\", \"K0\"])\n",
    "tmp4 = C_KU\n",
    "tmp5 = tmp4.splitUniform(32, depth=1)\n",
    "tmp6 = tmp5.splitUniform(4, depth=2)\n",
    "C_KU2U1U0 = tmp6\n",
    "C_KU2U1U0.setRankIds(rank_ids=[\"K\", \"U2\", \"U1\", \"U0\"])\n",
    "tmp7 = C_KU2U1U0\n",
    "tmp8 = tmp7.splitUniform(8, depth=0)\n",
    "C_K1K0U2U1U0 = tmp8\n",
    "C_K1K0U2U1U0.setRankIds(rank_ids=[\"K1\", \"K0\", \"U2\", \"U1\", \"U0\"])\n",
    "t_i1 = T_I1I0JU2U1U0.getRoot()\n",
    "C_U2K1K0U1U0 = C_K1K0U2U1U0.swizzleRanks(rank_ids=[\"U2\", \"K1\", \"K0\", \"U1\", \"U0\"])\n",
    "a_i1 = A_I1I0JK1K0.getRoot()\n",
    "c_u2 = C_U2K1K0U1U0.getRoot()\n",
    "canvas = createCanvas(A_I1I0JK1K0, C_U2K1K0U1U0, T_I1I0JU2U1U0)\n",
    "for i1_pos, (i1, (t_i0, a_i0)) in enumerate(t_i1 << a_i1):\n",
    "    for i0_pos, (i0, (t_j, a_j)) in enumerate(t_i0 << a_i0):\n",
    "        for j_pos, (j, (t_u2, a_k1)) in enumerate(t_j << a_j):\n",
    "            for u2_pos, (u2, (t_u1, c_k1)) in enumerate(t_u2 << c_u2):\n",
    "                for k1_pos, (k1, (a_k0, c_k0)) in enumerate(a_k1 & c_k1):\n",
    "                    for k0_pos, (k0, (a_val, c_u1)) in enumerate(a_k0 & c_k0):\n",
    "                        for u1_pos, (u1, (t_u0, c_u0)) in enumerate(t_u1 << c_u1):\n",
    "                            for u0_pos, (u0, (t_ref, c_val)) in enumerate(t_u0 << c_u0):\n",
    "                                t_ref += a_val * c_val\n",
    "                                canvas.addActivity((i1, i0, j, k1, k0), (u2, k1, k0, u1, u0), (i1, i0, j, u2, u1, u0), spacetime=((i1_pos, u1_pos, u0_pos), (i0_pos, j_pos, u2_pos, k1_pos, k0_pos)))\n",
    "tmp9 = T_I1I0JU2U1U0\n",
    "tmp10 = tmp9.mergeRanks(depth=3, levels=2, coord_style=\"absolute\")\n",
    "tmp11 = tmp10.mergeRanks(depth=0, levels=1, coord_style=\"absolute\")\n",
    "tmp11.setRankIds(rank_ids=[\"I\", \"J\", \"U\"])\n",
    "T_IJU = tmp11\n",
    "displayCanvas(canvas)\n",
    "Y_I1I0V1U2V0U1U0 = Tensor(rank_ids=[\"I1\", \"I0\", \"V1\", \"U2\", \"V0\", \"U1\", \"U0\"], name=\"Y\")\n",
    "tmp12 = T_IJU\n",
    "tmp13 = tmp12.uniform_slice(8)\n",
    "T_I1I0JU = tmp13\n",
    "T_I1I0JU.setRankIds(rank_ids=[\"I1\", \"I0\", \"J\", \"U\"])\n",
    "tmp14 = T_I1I0JU\n",
    "tmp15 = tmp14.splitUniform(32, depth=3)\n",
    "tmp16 = tmp15.splitUniform(4, depth=4)\n",
    "T_I1I0JU2U1U0 = tmp16\n",
    "T_I1I0JU2U1U0.setRankIds(rank_ids=[\"I1\", \"I0\", \"J\", \"U2\", \"U1\", \"U0\"])\n",
    "tmp17 = B_JV\n",
    "tmp18 = tmp17.splitUniform(8, depth=1)\n",
    "B_JV1V0 = tmp18\n",
    "B_JV1V0.setRankIds(rank_ids=[\"J\", \"V1\", \"V0\"])\n",
    "y_i1 = Y_I1I0V1U2V0U1U0.getRoot()\n",
    "t_i1 = T_I1I0JU2U1U0.getRoot()\n",
    "b_j = B_JV1V0.getRoot()\n",
    "canvas = createCanvas(T_I1I0JU2U1U0, B_JV1V0, Y_I1I0V1U2V0U1U0)\n",
    "for i1_pos, (i1, (y_i0, t_i0)) in enumerate(y_i1 << t_i1):\n",
    "    for i0_pos, (i0, (y_v1, t_j)) in enumerate(y_i0 << t_i0):\n",
    "        for j_pos, (j, (t_u2, b_v1)) in enumerate(t_j & b_j):\n",
    "            for v1_pos, (v1, (y_u2, b_v0)) in enumerate(y_v1 << b_v1):\n",
    "                for u2_pos, (u2, (y_v0, t_u1)) in enumerate(y_u2 << t_u2):\n",
    "                    for v0_pos, (v0, (y_u1, b_val)) in enumerate(y_v0 << b_v0):\n",
    "                        for u1_pos, (u1, (y_u0, t_u0)) in enumerate(y_u1 << t_u1):\n",
    "                            for u0_pos, (u0, (y_ref, t_val)) in enumerate(y_u0 << t_u0):\n",
    "                                y_ref += t_val * b_val\n",
    "                                canvas.addActivity((i1, i0, j, u2, u1, u0), (j, v1, v0), (i1, i0, v1, u2, v0, u1, u0), spacetime=((i1_pos, u1_pos, u0_pos), (i0_pos, j_pos, v1_pos, u2_pos, v0_pos)))\n",
    "tmp19 = Y_I1I0V1U2V0U1U0\n",
    "tmp20 = tmp19.swizzleRanks(rank_ids=[\"I1\", \"I0\", \"V1\", \"V0\", \"U2\", \"U1\", \"U0\"])\n",
    "tmp21 = tmp20.mergeRanks(depth=4, levels=2, coord_style=\"absolute\")\n",
    "tmp22 = tmp21.mergeRanks(depth=0, levels=1, coord_style=\"absolute\")\n",
    "tmp23 = tmp22.mergeRanks(depth=1, levels=1, coord_style=\"absolute\")\n",
    "tmp23.setRankIds(rank_ids=[\"I\", \"V\", \"U\"])\n",
    "Y_IVU = tmp23\n",
    "displayCanvas(canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4313cf2d-ce0e-4f64-93eb-3c6379b3b414",
   "metadata": {},
   "source": [
    "### Check Results\n",
    "\n",
    "Check that above code (generated or provided) computes the correct result.\n",
    "\n",
    "**Note**: Should be used after executing the HiFiber loopnest (one of the above cells)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731ddd7c-3a2d-4a1e-9f78-9962d0e878bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.check_TTMc(A_IJK, B_JV, C_KU, Y_IVU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece2a508-a57c-4879-905c-361ebe204a15",
   "metadata": {},
   "source": [
    "## Kernel: GEMM and SpMM\n",
    "\n",
    "**Note:**\n",
    "1. The dataflow of GEMM and SpMM for Tensaurus is relatively simple because the authors assume the operand matrix is dense while the input matrix A can be dense or sparse.\n",
    "2. Temporary shift registers are not used for GEMM and SpMM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566cdceb-c100-4e74-af6d-6684612e7e04",
   "metadata": {},
   "source": [
    "### Initialization\n",
    "\n",
    "Initialize the input tensors. Tensor shapes and densities can be modified below.\n",
    "\n",
    "**Warning:** Large tensors will overwhelm the video generation. Either:\n",
    "1. Use small tensors; as a rule of thumb, fewer than 60 computes (e.g., multiplications) should be required.\n",
    "2. Do not generate a video; remove the `spacetime` specification from the `mapping` before compiling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d560adad-8ca1-4723-ba99-14e953a68e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "I = 4\n",
    "J = 4\n",
    "K = 4\n",
    "\n",
    "density = [0.8, 0.8]\n",
    "seed = 0\n",
    "\n",
    "A_IJ = Tensor.fromRandom(rank_ids=[\"I\", \"J\"], shape=[I, J], seed=seed, density=density, name=\"A\")\n",
    "B_JK = Tensor.fromRandom(rank_ids=[\"J\", \"K\"], shape=[J, K], seed=seed + 1, density=[1,1], name=\"B\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ae87aa-32dd-4b4b-b602-b13efdd0d5e8",
   "metadata": {},
   "source": [
    "Execute the following cell if you wish to visualize tensor `A_IJ` and `B_JK`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e583e1e-27ba-43fb-9577-2eaa60bdf771",
   "metadata": {},
   "outputs": [],
   "source": [
    "displayTensor(A_IJ)\n",
    "displayTensor(B_JK)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a682ac-b6ea-48b4-ac19-7f53d57ad90f",
   "metadata": {},
   "source": [
    "### Compile from TeAAL Specification and Run\n",
    "\n",
    "Below is the TeAAL specification for matrix-matrix multiplication on Tensaurus. To simulate the accelerator:\n",
    "1. Compile it to HiFiber by running the cell, inserting a new cell\n",
    "2. Run the new cell, which will\n",
    "    - Execute the kernel\n",
    "    - Generate visualizations of the actions of the kernel\n",
    "\n",
    "Remember, if you are using large tensors, remove the spacetime specification to generate a kernel that does not produce videos. Outputs can still be checked below.\n",
    "\n",
    "#### Notes\n",
    "\n",
    "- Small tensors are required for video generation. If you are using large tensors, remove the spacetime specification to generate a kernel that does not produce videos. Outputs can still be checked below.\n",
    "- The visualizations generated by TeAAL do not account for Tensaurus's partitioning technique and sparse tensor storage format. A modified HiFiber visualization that implements uniform slice partitioning is provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774e284b-1b04-435b-a521-a92c9720b2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml = \"\"\"\n",
    "einsum:\n",
    "    declaration:\n",
    "        A: [I, J]\n",
    "        B: [J, K]\n",
    "        Y: [I, K]\n",
    "    expressions:\n",
    "        - Y[i, k] = A[i, j] * B[j, k]\n",
    "mapping:\n",
    "    rank-order:\n",
    "        A: [I, J]\n",
    "        B: [J, K]\n",
    "        Y: [I, K]\n",
    "    partitioning:\n",
    "        Y:\n",
    "            I: [uniform_shape(8)]\n",
    "            K: [uniform_shape(32), uniform_shape(4)]\n",
    "    loop-order:\n",
    "        Y: [I1, I0, K2, J, K1, K0]\n",
    "    spacetime:\n",
    "        Y:\n",
    "            space: [I1, K1, K0]\n",
    "            time: [I0, K2, J]\n",
    "\"\"\"\n",
    "\n",
    "utils.compile(yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ce4a34-9b08-48cb-a07a-eab8e67b2179",
   "metadata": {},
   "source": [
    "### Visualize Uniform Slice Partitioning\n",
    "\n",
    "Tensaurus uses the compressed interleaved sparse slice (CISS) storage format to achieve a higher memory bandwidth. Since the CISS format implements uniform slice partitioning, the HiFiber loop nest below accounts for this partitioning  technique. Note that the *only* difference between the code generated by the above TeAAL specification and the below HiFiber code is the replacement of `splitUniform(8, depth=0)` with `uniform_slice(8)` for tensor `A` when partitioning rank `I`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86967e5-6df7-465e-a983-d17bdbbc2647",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_I1I0K2K1K0 = Tensor(rank_ids=[\"I1\", \"I0\", \"K2\", \"K1\", \"K0\"], name=\"Y\")\n",
    "tmp0 = A_IJ\n",
    "tmp1 = tmp0.uniform_slice(8)\n",
    "A_I1I0J = tmp1\n",
    "A_I1I0J.setRankIds(rank_ids=[\"I1\", \"I0\", \"J\"])\n",
    "tmp2 = B_JK\n",
    "tmp3 = tmp2.splitUniform(32, depth=1)\n",
    "tmp4 = tmp3.splitUniform(4, depth=2)\n",
    "B_JK2K1K0 = tmp4\n",
    "B_JK2K1K0.setRankIds(rank_ids=[\"J\", \"K2\", \"K1\", \"K0\"])\n",
    "y_i1 = Y_I1I0K2K1K0.getRoot()\n",
    "B_K2JK1K0 = B_JK2K1K0.swizzleRanks(rank_ids=[\"K2\", \"J\", \"K1\", \"K0\"])\n",
    "a_i1 = A_I1I0J.getRoot()\n",
    "b_k2 = B_K2JK1K0.getRoot()\n",
    "canvas = createCanvas(A_I1I0J, B_K2JK1K0, Y_I1I0K2K1K0)\n",
    "for i1_pos, (i1, (y_i0, a_i0)) in enumerate(y_i1 << a_i1):\n",
    "    for i0_pos, (i0, (y_k2, a_j)) in enumerate(y_i0 << a_i0):\n",
    "        for k2_pos, (k2, (y_k1, b_j)) in enumerate(y_k2 << b_k2):\n",
    "            for j_pos, (j, (a_val, b_k1)) in enumerate(a_j & b_j):\n",
    "                for k1_pos, (k1, (y_k0, b_k0)) in enumerate(y_k1 << b_k1):\n",
    "                    for k0_pos, (k0, (y_ref, b_val)) in enumerate(y_k0 << b_k0):\n",
    "                        y_ref += a_val * b_val\n",
    "                        canvas.addActivity((i1, i0, j), (k2, j, k1, k0), (i1, i0, k2, k1, k0), spacetime=((i1_pos, k1_pos, k0_pos), (i0_pos, k2_pos, j_pos)))\n",
    "tmp5 = Y_I1I0K2K1K0\n",
    "tmp6 = tmp5.mergeRanks(depth=2, levels=2, coord_style=\"absolute\")\n",
    "tmp7 = tmp6.mergeRanks(depth=0, levels=1, coord_style=\"absolute\")\n",
    "tmp7.setRankIds(rank_ids=[\"I\", \"K\"])\n",
    "Y_IK = tmp7\n",
    "displayCanvas(canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950c5422-11e9-4c41-b3ec-a62e865e1596",
   "metadata": {},
   "source": [
    "### Check Results\n",
    "\n",
    "Check that above code (generated or provided) computes the correct result.\n",
    "\n",
    "**Note**: Should be used after executing the HiFiber loopnest (one of the above cells)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ac61ed-43fa-48c6-a2ad-49ee064cb1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.check_matrix_matrix_mul(A_IJ, B_JK, Y_IK)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcbc6a6-9c9c-43e3-bc43-d4b38e81a047",
   "metadata": {},
   "source": [
    "## Kernel: GEMV and SpMV\n",
    "\n",
    "**Note:**\n",
    "1. The dataflow of GEMV and SpMV for Tensaurus is relatively simple because the authors assume that the operand vector is dense while the input matrix A can be dense or sparse.\n",
    "2. Temporary shift registers are not used for GEMV and SpMV.\n",
    "3. Only one output shift register is utilized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0b5634-a014-4a6a-9a20-1fba69465908",
   "metadata": {},
   "source": [
    "### Initialization\n",
    "\n",
    "Initialize the input tensors. Tensor shapes and densities can be modified below.\n",
    "\n",
    "**Warning:** Large tensors will overwhelm the video generation. Either:\n",
    "1. Use small tensors; as a rule of thumb, fewer than 60 computes (e.g., multiplications) should be required.\n",
    "2. Do not generate a video; remove the `spacetime` specification from the `mapping` before compiling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dc6dc7-97ad-4525-9cd2-d1f6712478a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "I = 4\n",
    "J = 4\n",
    "\n",
    "densityA = [0.9, 0.9]\n",
    "seed = 0\n",
    "\n",
    "A_IJ = Tensor.fromRandom(rank_ids=[\"I\", \"J\"], shape=[I, J], seed=seed, density=densityA, name=\"A\")\n",
    "B_J = Tensor.fromRandom(rank_ids=[\"J\"], shape=[J], seed=seed + 1, density=[1], name=\"B\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40d689b-c71e-4d2d-8766-2b7af02e366a",
   "metadata": {},
   "source": [
    "Execute the following cell if you wish to visualize the tensor `A_IJ` and `B_J`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93646bf-4857-4193-b34d-66f4cfc17610",
   "metadata": {},
   "outputs": [],
   "source": [
    "displayTensor(A_IJ)\n",
    "displayTensor(B_J)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dafdee-c3ec-4fcc-8d30-562a89fcf1e4",
   "metadata": {},
   "source": [
    "### Compile from TeAAL Specification and Run\n",
    "\n",
    "Below is the TeAAL specification for matrix-vector multiplication on Tensaurus. To simulate the accelerator:\n",
    "1. Compile it to HiFiber by running the cell, inserting a new cell\n",
    "2. Run the new cell, which will\n",
    "    - Execute the kernel; multiplying the defined matrices in each section\n",
    "    - Generate visualizations of the actions of the kernel\n",
    "\n",
    "Remember, if you are using large tensors, remove the spacetime specification to generate a kernel that does not produce videos. Outputs can still be checked below.\n",
    "\n",
    "#### Notes\n",
    "\n",
    "- Small tensors are required for video generation. If you are using large tensors, remove the spacetime specification to generate a kernel that does not produce videos. Outputs can still be checked below.\n",
    "- The visualizations generated by TeAAL do not account for Tensaurus's partitioning technique and sparse tensor storage format. A modified HiFiber visualization that implements uniform slice partitioning is provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419d8aa3-3d5d-47f6-b41f-816c3ff95632",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml = \"\"\"\n",
    "einsum:\n",
    "    declaration:\n",
    "        A: [I, J]\n",
    "        B: [J]\n",
    "        Y: [I]\n",
    "    expressions:\n",
    "        - Y[i] = A[i, j] * B[j]\n",
    "mapping:\n",
    "    rank-order:\n",
    "        A: [I, J]\n",
    "        B: [J]\n",
    "        Y: [I]\n",
    "    partitioning:\n",
    "        Y:\n",
    "            I: [uniform_shape(8)]\n",
    "    loop-order:\n",
    "        Y: [I1, I0, J]\n",
    "    spacetime:\n",
    "        Y:\n",
    "            space: [I1]\n",
    "            time: [I0, J]\n",
    "\"\"\"\n",
    "\n",
    "utils.compile(yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afa15f9-7a16-4cb5-a8e6-2fa38270adba",
   "metadata": {},
   "source": [
    "### Visualize Uniform Slice Partitioning\n",
    "\n",
    "Tensaurus uses the compressed interleaved sparse slice (CISS) storage format to achieve a higher memory bandwidth. Since the CISS format implements uniform slice partitioning, the HiFiber loop nest below accounts for this partitioning  technique. Note that the *only* difference between the code generated by the above TeAAL specification and the below HiFiber code is the replacement of `splitUniform(8, depth=0)` with `uniform_slice(8)` for tensor `A` when partitioning rank `I`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f818fc-e8ae-40fc-bbb0-8c3953c8e920",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_I1I0 = Tensor(rank_ids=[\"I1\", \"I0\"], name=\"Y\")\n",
    "tmp0 = A_IJ\n",
    "tmp1 = tmp0.uniform_slice(8)\n",
    "A_I1I0J = tmp1\n",
    "A_I1I0J.setRankIds(rank_ids=[\"I1\", \"I0\", \"J\"])\n",
    "y_i1 = Y_I1I0.getRoot()\n",
    "b_j = B_J.getRoot()\n",
    "a_i1 = A_I1I0J.getRoot()\n",
    "canvas = createCanvas(A_I1I0J, B_J, Y_I1I0)\n",
    "for i1_pos, (i1, (y_i0, a_i0)) in enumerate(y_i1 << a_i1):\n",
    "    for i0_pos, (i0, (y_ref, a_j)) in enumerate(y_i0 << a_i0):\n",
    "        for j_pos, (j, (a_val, b_val)) in enumerate(a_j & b_j):\n",
    "            y_ref += a_val * b_val\n",
    "            canvas.addActivity((i1, i0, j), (j,), (i1, i0), spacetime=((i1_pos,), (i0_pos, j_pos)))\n",
    "tmp2 = Y_I1I0\n",
    "tmp3 = tmp2.mergeRanks(depth=0, levels=1, coord_style=\"absolute\")\n",
    "tmp3.setRankIds(rank_ids=[\"I\"])\n",
    "Y_I = tmp3\n",
    "displayCanvas(canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b7f978-b8d7-447a-8306-74134a5817dc",
   "metadata": {},
   "source": [
    "### Check Results\n",
    "\n",
    "Check that above code (generated or provided) computes the correct result.\n",
    "\n",
    "**Note**: Should be used after executing the HiFiber loopnest (one of the above cells)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7621983c-2ae9-4445-ba0e-0ab3c8a57080",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.check_matrix_vector_mul(A_IJ, B_J, Y_I)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
