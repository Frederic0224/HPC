{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c1cd370-ca5d-4582-b112-e3afcde6a8b0",
   "metadata": {},
   "source": [
    "# Dynamic Reflexive Tiling (DRT)\n",
    "\n",
    "This notebook reproduces the salient characteristics of [Dynamic Reflexive Tiling](https://dl.acm.org/doi/10.1145/3582016.3582064) on accelerators of different dataflows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bb7cb5-fcec-4f86-a65b-6f32f04f9533",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Import the necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf89956-1028-4201-9122-3c72516d5ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HiFiber boilerplate\n",
    "\n",
    "from fibertree_bootstrap import *\n",
    "\n",
    "fibertree_bootstrap(style=\"tree\", animation='movie')\n",
    "\n",
    "# Compilation boilerplate\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "from src import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d14dda1-fe00-4505-9c32-4dc0d65b86f6",
   "metadata": {},
   "source": [
    "## Dynamic Reflexive Tiling\n",
    "Dynamic Reflexive Tiling (DRT) is an approach to build dynamic-nonuniform-coordinate (D-N-C) tiles at different levels of the memory hierarchy. Since sparse tensor algebra applications are often memory bound, DRT increases reuse by maximizing tile size based on the amount of memory available.\n",
    "\n",
    "Since DRT is not supported by TeAAL at the moment, the HiFiber code in this section will define the necessary functions that will describe DRT. Please note that while DRT supports the tiling of tensors with more than 2 dimensions, the functions below are implemented to support 2-tensors (matrices) only for simplicity. Additionally, note that while the implementation mimics the behavior of DRT, the functions below may behave differently compared to the actual DRT implementation due to simplications and assumptions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa30cd9-ee27-42d0-9962-74184dec9cbb",
   "metadata": {},
   "source": [
    "The tiling process starts by pre-processing input tensors into micro tiles. The support of coarsening allows the process to more efficiently produce macro tiles dynamically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d156dac-1865-42d0-8fdb-fed6d48921fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "def generateMicroTiles(self, micro_tile_size):\n",
    "    \"\"\"Returns a tensor partitioned into micro tiles of a specific size\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    self: tensor\n",
    "        The input tensor\n",
    "    micro_tile_size: integer\n",
    "        Specifies the tile size of a micro tile\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    partitioned_tensor: tensor\n",
    "        A tensor partitioned into static-uniform-coordinate micro tiles of size MICRO_TILE_SIZE.\n",
    "    \"\"\"\n",
    "    number_of_dimensions = self.getDepth()\n",
    "    scope = int(sqrt(micro_tile_size))\n",
    "    for i in range(number_of_dimensions-1, -1, -1):\n",
    "        self = self.splitUniform(scope, depth=i)\n",
    "    partitioned_tensor = self.swizzleRanks(rank_ids=sorted(self.getRankIds(), key=lambda x: x[1:], reverse=True))\n",
    "    return partitioned_tensor\n",
    "Tensor.generateMicroTiles = generateMicroTiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833cf283-25e1-4cc2-97ea-fdc8537d8674",
   "metadata": {},
   "source": [
    "After patitioning a tensor into micro tiles, we  also need to compute the footprint of each micro tile. Computing the footprint allows macro tile build without further introspection of the micro tile's metadata in the future. The function below generates the micro tile footprint given that tensors are stored using a compressed coordinate and segment array data structure.\n",
    "\n",
    "It is assumed that the data themselves are 64-bit wide while elements in the segment and coordinate arrays are 32-bit wide. In our implementation, it is also assumed that the elements in the data, segment and coordinate arrays are all that consume memory space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c420b4-7320-48b4-81bc-bba8165902fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateMicroTileFootprint(self, micro_tile_size):\n",
    "    \"\"\"Returns a tensor (fiber-tree representation) containing the micro tile footprints of the input tensor\n",
    "    Parameters\n",
    "    ----------\n",
    "    self: tensor\n",
    "        The input tensor\n",
    "    micro_tile_size: integer\n",
    "        Specifies the tile size of a micro tile\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    footprint: tensor\n",
    "        A tensor containing the data footprint of each micro tile in the input tensor.\n",
    "    \"\"\"\n",
    "    span = int(sqrt(micro_tile_size))\n",
    "    footprint = Tensor(rank_ids=(self.getRankIds()[:2]), name=\"footprint\")\n",
    "    footprint_i1 = footprint.getRoot()\n",
    "    self_i1 = self.getRoot()\n",
    "    for i1, self_j1 in self_i1:\n",
    "        for j1, self_k0 in self_j1:\n",
    "            footprint_ref = footprint_i1.getPayloadRef(i1, j1)\n",
    "            memory_req = self_k0.countValues() * (64 + 32) # bits required to store all data + the coordinate array of a micro tile\n",
    "            \n",
    "            # bits required to store the segment array of a micro tile\n",
    "            if i1 + span > self.getShape()[0]:\n",
    "                memory_req += 32 * (self.getShape()[0] - i1 + 1)\n",
    "            else:\n",
    "                memory_req += 32 * (span + 1)\n",
    "            \n",
    "            footprint_ref += memory_req # records the data footprint of a micro tile\n",
    "    return footprint\n",
    "Tensor.calculateMicroTileFootprint = calculateMicroTileFootprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103512c6-501d-46d4-a0cd-2fc28e790200",
   "metadata": {},
   "source": [
    "Next, the `dims` function is implemented. The function is necessary for many other functions to work below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8084d9-82ad-4a32-9571-84b760abff51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dims(self):\n",
    "    \"\"\"Returns rank ids of the micro tiles in a tensor\n",
    "    Parameters\n",
    "    ----------\n",
    "    self: a tensor\n",
    "        The input tensor\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    rank_ids: list of strings\n",
    "        All rank ids required to specify a micro tile in a tensor\n",
    "    \"\"\"\n",
    "    rank_ids = [rank for rank in self.getRankIds() if rank[-1] == '1'] # we only want to rank ids of the micro tiles\n",
    "    return rank_ids\n",
    "Tensor.dims = dims"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bcd8a0-12d8-4f88-9e03-da646cb56207",
   "metadata": {},
   "source": [
    "In the DRT paper, the authors implements DRT by growing tensors in the order of their stationarity. This process is designed to prioritize reuse for more stationary tensors. To model this behavior, the `sortByStationarity` function is needed to order tensors by their stationarity given a loop order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7075381-5b2a-4f49-8c87-3c06328ea33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortByStationarity(tensors, loop_order):\n",
    "    \"\"\"Returns the tensors ordered by stationarity\n",
    "    Parameters\n",
    "    ----------\n",
    "    tensors: list of tensors\n",
    "        A list of input tensors\n",
    "\n",
    "    loop_order: list of strings\n",
    "        Gives the loop order at which each rank is processed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tensors: list of tensors\n",
    "        A sorted list of tensors based on their stationarity\n",
    "    \"\"\"\n",
    "    rank_ids = []\n",
    "    for tensor in tensors:\n",
    "        rank_ids.append(tensor.getRankIds())\n",
    "    order = []\n",
    "    for ids in rank_ids:\n",
    "        order.append(sum([loop_order.index(x) for x in ids if x in loop_order]))\n",
    "    return list(sorted(tensors, key=lambda x: order[tensors.index(x)]))\n",
    "\n",
    "Tensor.sortByStationarity = sortByStationarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45791334-a560-44bf-8643-b5049066dfd3",
   "metadata": {},
   "source": [
    "After being able to choose the order at which each tensor will be processed, we also need to select the dimension along which a tile will grow. In section 3.2, the DRT paper mentioned that DRT prioritizes contracted dimensions before moving onto uncontracted dimensions when growing a macro tile. This is designed to maximize output locality. To mimic this behavior, we will implement the `orderDims` and `selectDimToGrow` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdf5be7-7ba2-4487-af7a-980c67e714c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def orderDims(tensors, dims):\n",
    "    \"\"\"Orders the dimensions based on the order they will be processed by DRT\n",
    "    Parameters\n",
    "    ----------\n",
    "    tensors: list of tensors\n",
    "        All of the tensors involved in the computation\n",
    "    dims: list of strings\n",
    "        All rank ids to be considered\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dims: list of strings\n",
    "        A sorted list of rank ids according to their priorities (contracted dimensions are prioritized)\n",
    "    \"\"\"\n",
    "    count = []\n",
    "    for dimension in dims:\n",
    "        track = 0\n",
    "        for tensor in tensors:\n",
    "            if dimension in tensor.getRankIds():\n",
    "                track += 1\n",
    "        count.append(track)\n",
    "    dims = list(sorted(dims, key=lambda x: count[dims.index(x)], reverse = True)) # sort the ranks by their priority\n",
    "    return dims\n",
    "Tensor.orderDims = orderDims\n",
    "\n",
    "def selectDimToGrow(self, tensors, constraints):\n",
    "    \"\"\"Returns the dimension to grow a macro tile\n",
    "    Parameters\n",
    "    ----------\n",
    "    self: a tensor\n",
    "        The tensor of interest\n",
    "    tensors: list of tensors\n",
    "        All of the tensors involved in the computation\n",
    "    constraints: a dictionary\n",
    "        Specifies if a dimension is constrained\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dimension: a string\n",
    "        The rank id that specifise the rank along which growDims will be applied to\n",
    "    \"\"\"\n",
    "    for dimension in Tensor.orderDims(tensors, list(constraints.keys())):\n",
    "        if dimension in self.getRankIds() and constraints[dimension] is None: # check if a dimension is constrained\n",
    "            return dimension\n",
    "    return None # all dimensions are constrained\n",
    "Tensor.selectDimToGrow = selectDimToGrow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0ca144-f86d-44f6-aa5e-9d119145866f",
   "metadata": {},
   "source": [
    "Now we can move on to functions that will be responsible for growing a macro tile. A simple function `grow` is introduced below. The function will simply modify the dictionary `dim_span`, keeping track of the macro tile's shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5434bb42-9c34-4fa4-81ab-f457ba440513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grow(dim, n, dim_span):\n",
    "    \"\"\" Grows the input tensor by N micro tiles along DIM by updating DIM_SPAN\n",
    "    Parameters\n",
    "    ----------\n",
    "    dim: a string\n",
    "        The dimension along which a tile grows\n",
    "    n: integer\n",
    "        The amount by which a tile will grow along DIM\n",
    "    dim_span: dictionary\n",
    "        Specifies the shape of the current macro tile\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "\n",
    "    Side effects\n",
    "    -------\n",
    "    dim_span: dictionary\n",
    "        Function modifies DIM_SPAN\n",
    "    \"\"\"\n",
    "    dim_span[dim][1] += n\n",
    "Tensor.grow = grow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23258d5-0261-43ff-a195-25cb9e42ecdb",
   "metadata": {},
   "source": [
    "Before growing a macro tile using `grow`, we need to check if it is possible to grow the macro tile along a dimension in the first place. The function `canGrow` consider memory constraints of growing a macro tile. Remember that we assume that all metadata are 32 bits wide while the data themselves are 64 bits wide. Additionally, we assume that tensors are stored using a coordinate and segment array data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f9a234-9fa3-4d9b-aafa-62b15bdf8ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def canGrow(self, dim, n, dim_span, micro_tile_size, micro_tile_loop_order, allocated_buffer_size, outer_dim):\n",
    "    \"\"\"Checks if it is possible for the input tensor to grow by N micro tiles along DIM\n",
    "    Parameters\n",
    "    ----------\n",
    "    self: a tensor\n",
    "        The tensor of interest\n",
    "    dim: a string\n",
    "        The dimension along which a tile grows\n",
    "    n: integer\n",
    "        The amount by which a tile will grow along DIM\n",
    "    dim_span: dictionary\n",
    "        Specifies the shape of the current macro tile\n",
    "    micro_tile_size: integer\n",
    "        Specifies the tile size of a micro tile\n",
    "    micro_tile_loop_order: list of strings\n",
    "        Specifies the loop order of which a micro tile is processed\n",
    "    allocated_buffer_size: integer\n",
    "        The amount of memory allocated to the tensor of interest at the next level of the memory hierarchy (in bits)\n",
    "    outer_dim: string\n",
    "        The dimension that will be used for the segment array\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    can_grow: boolean\n",
    "        Indicates whether or not growing N micro tiles along DIM is possible\n",
    "    \"\"\"\n",
    "    memory_req = 32 # number of bits required to store the first element of the segment array\n",
    "    difference = int(sqrt(micro_tile_size))\n",
    "    shape = self.getShape()[self.getRankIds().index(dim)]\n",
    "    if (dim_span[dim][1] + n - 2) * difference >= shape: # cannot access non-existent micro tiles\n",
    "        return False\n",
    "    dim_span[dim][1] += n\n",
    "\n",
    "    # calculate memory required\n",
    "    microtile_footprint = self.getMicroTileFootprint_LoopOrder(micro_tile_size, micro_tile_loop_order)\n",
    "    microtile_footprint_i = microtile_footprint.getRoot()\n",
    "    for i, microtile_footprint_j in microtile_footprint_i:\n",
    "        if i >= dim_span[self.getRankIds()[0]][1] * difference: # checks if we are selecting micro tiles out of scope\n",
    "            break\n",
    "        if i >= dim_span[self.getRankIds()[0]][0] * difference:\n",
    "            for j, val in microtile_footprint_j:\n",
    "                if j >= dim_span[self.getRankIds()[1]][1] * difference: # checks if we are selecting micro tiles out of scope\n",
    "                    break\n",
    "                if j >= dim_span[self.getRankIds()[1]][0] * difference:\n",
    "                    memory_req += val # micro tile\n",
    "                    memory_req += 3 * 32 # coordinate array + micro tile size metadata + micro tile pointer\n",
    "    segment_span = dim_span[outer_dim]\n",
    "    memory_req += (segment_span[1] - segment_span[0]) * 32\n",
    "    # return can_grow and revert unwanted changed to dim_span\n",
    "    # print(\"Can grow?: Macro tile size: \" + str(dim_span) + \". Required memory: \" + str(memory_req) + \".\" + \"Memory given: \" + str(allocated_buffer_size))\n",
    "    dim_span[dim][1] -= n\n",
    "    can_grow = memory_req <= allocated_buffer_size\n",
    "    return can_grow\n",
    "Tensor.canGrow = canGrow\n",
    "\n",
    "def getMicroTileFootprint_LoopOrder(self, micro_tile_size, micro_tile_loop_order):\n",
    "    \"\"\"calculates the micro tile footprint by first deciding which rank should be used for the segment and coordinate array.\"\"\"\n",
    "    order = dict()\n",
    "    originalRankIds = list(self.getRankIds())\n",
    "    for ID in originalRankIds[:2]:\n",
    "        order[ID] = micro_tile_loop_order.index(ID[0] + \".0\")\n",
    "    changedRankIds = list(sorted(originalRankIds[:2], key=lambda x: order[x])) + originalRankIds[2:]\n",
    "    res = self.swizzleRanks(rank_ids=changedRankIds).calculateMicroTileFootprint(micro_tile_size)\n",
    "    res = res.swizzleRanks(rank_ids=originalRankIds[:2])\n",
    "    return res\n",
    "Tensor.getMicroTileFootprint_LoopOrder = getMicroTileFootprint_LoopOrder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd36178-0b73-41e7-aca6-40f6d4d426d4",
   "metadata": {},
   "source": [
    "With `selectDimToGrow`, `grow` and `canGrow` we can now implement `growDims` to grow a macro tile until all dimensions of a tensor is constrained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e847370-8fa3-4d6b-9c78-3d08be21c676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def growDims(self, tensors, n, dim_span, constraints, micro_tile_size, micro_tile_loop_order, allocated_buffer_size, outer_dim):\n",
    "    \"\"\"Grows a macro tile until all of a tensor's dimensions are constrained\n",
    "    Parameters\n",
    "    ----------\n",
    "    self: tensor\n",
    "        The tensor of interest\n",
    "    tensors: list of tensors\n",
    "        All tensors considered for the computation\n",
    "    n: integer\n",
    "        The step size everytime DRT grows a macro tile\n",
    "    dim_span: dictionary\n",
    "        Specifies the shape of the current macro tile\n",
    "    constraints: dictionary\n",
    "        Specifies if a dimension is constrained\n",
    "    micro_tile_size: integer\n",
    "        Specifies the tile size of a micro tile\n",
    "    micro_tile_loop_order: list of strings\n",
    "        Specifies the loop order of which a micro tile is processed\n",
    "    allocated_buffer_size: integer\n",
    "        The amount of memory allocated to the tensor of interest at the next level of the memory hierarchy\n",
    "    outer_dim: string\n",
    "        The dimension that will be used for the segment array\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "\n",
    "    Side effects\n",
    "    -------\n",
    "    dim_span: dictionary\n",
    "        Modifies dim_span to reflect the current shape of the macro tile\n",
    "    constraints: dictionary\n",
    "        Modifies constraints, a dictionary that tracks the constraints for each dimension of a tensor\n",
    "    \"\"\"\n",
    "    dim = self.selectDimToGrow(tensors, constraints)\n",
    "    while dim is not None:\n",
    "        if self.canGrow(dim, n, dim_span, micro_tile_size, micro_tile_loop_order, allocated_buffer_size, outer_dim):\n",
    "            Tensor.grow(dim, n, dim_span)\n",
    "        else:\n",
    "            constraints[dim] = dim_span[dim]\n",
    "            dim = self.selectDimToGrow(tensors, constraints)\n",
    "Tensor.growDims = growDims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542021da-7530-4504-9822-fc554c525262",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_macro_tile(self, constraints, micro_tile_size):\n",
    "    \"\"\"Prints a macro tile given a set of constraints\"\"\"\n",
    "    dims = self.getRankIds()\n",
    "    Z = Tensor(rank_ids=(self.getRankIds()))\n",
    "    Z.setName(\"Macro tile \" + self.getName()[0])\n",
    "    z_i1 = Z.getRoot()\n",
    "    self_i = self.getRoot()\n",
    "    difference = int(sqrt(micro_tile_size))\n",
    "    for i, self_j in self_i:\n",
    "        if i >= constraints[self.getRankIds()[0]][1] * difference: # checks if we are selecting micro tiles out of scope\n",
    "            break\n",
    "        if i >= constraints[self.getRankIds()[0]][0] * difference:\n",
    "            for j, self_k in self_j:\n",
    "                if j >= constraints[self.getRankIds()[1]][1] * difference: # checks if we are selecting micro tiles out of scope\n",
    "                    break\n",
    "                if j >= constraints[self.getRankIds()[1]][0] * difference:\n",
    "                    z_k = z_i1.getPayloadRef(i, j)\n",
    "                    z_k <<= self_k\n",
    "    displayTensor(Z)\n",
    "Tensor.print_macro_tile = print_macro_tile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47d921f-8155-4081-856c-29fb0fc5cf5b",
   "metadata": {},
   "source": [
    "Finally, the function responsible for the entire DRT process is implemented below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ca9c90-6d9a-4df8-9536-ac391fefc88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DRT(tensors, loop_order, init_tile_size, micro_tile_size, micro_tile_loop_order, buffer_size):\n",
    "    \"\"\" Gets the next macro tile\n",
    "    Parameters\n",
    "    ----------\n",
    "    tensors: list of tensors\n",
    "        Includes all tensors processed\n",
    "    loop_order: list of strings\n",
    "        Specifies the loop order of the kernel\n",
    "    init_tile_size: dictionary\n",
    "        Gives the initial macro tile size\n",
    "    micro_tile_size: integer\n",
    "        Specifies the tile size of a micro tile\n",
    "    micro_tile_loop_order: list of strings\n",
    "        Specifies the loop order of which a micro tile is processed\n",
    "    buffer_size: integer\n",
    "        The size of the buffer DRT is building a macro tile for in bits\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    all_dims = []\n",
    "\n",
    "    # Prepare all tensors for processing\n",
    "    for tensor in tensors:\n",
    "        tensor = tensor.swizzleRanks(rank_ids = Tensor.orderDims(tensors, tensor.getRankIds()[0:2]) + Tensor.orderDims(tensors, tensor.getRankIds()[2:]))\n",
    "        all_dims.append(set(tensor.dims()))\n",
    "\n",
    "    # Find all dimensions involved\n",
    "    all_dims = all_dims[0].union(all_dims[1])\n",
    "\n",
    "    # Set up constrains and dim_span. Both are needed for function calls later\n",
    "    constraints = {dim: None for dim in all_dims}\n",
    "    dim_span =  {dim: init_tile_size[dim].copy() for dim in all_dims}\n",
    "\n",
    "    n = 1\n",
    "    tensors = Tensor.sortByStationarity(tensors, loop_order)\n",
    "    tensor_A = tensors[0]\n",
    "    tensor_B = tensors[1]\n",
    "    buffer_allocation = buffer_size // 3\n",
    "    \n",
    "    contracted_dim = Tensor.orderDims(tensors, tensor_A.getRankIds()[0:2])[0]\n",
    "    A_uncontracted_dim = Tensor.orderDims(tensors, tensor_A.getRankIds()[0:2])[1]\n",
    "    B_uncontracted_dim = Tensor.orderDims(tensors, tensor_B.getRankIds()[0:2])[1]\n",
    "\n",
    "    A_constrain_contracted_dim = True\n",
    "    if loop_order.index(contracted_dim) > loop_order.index(A_uncontracted_dim):\n",
    "        A_constrain_contracted_dim = False\n",
    "    B_constrain_contracted_dim = True\n",
    "    if loop_order.index(contracted_dim) > loop_order.index(B_uncontracted_dim):\n",
    "        B_constrain_contracted_dim = False\n",
    "\n",
    "    if A_constrain_contracted_dim:\n",
    "        A_dim_one = contracted_dim\n",
    "        A_dim_two = A_uncontracted_dim\n",
    "    else:\n",
    "        A_dim_one = A_uncontracted_dim\n",
    "        A_dim_two = contracted_dim\n",
    "    \n",
    "    # grow along contracted_dim\n",
    "    dim_span[A_dim_one] = [0, 0]\n",
    "    while tensor_A.canGrow(A_dim_one, n, dim_span, micro_tile_size, micro_tile_loop_order, buffer_allocation, A_dim_one):\n",
    "        dim_span[A_dim_one][1] += init_tile_size[A_dim_one][1]\n",
    "        # grow along A_dim_two\n",
    "        constraints[A_dim_two] = None\n",
    "        dim_span[A_dim_two] = init_tile_size[A_dim_two].copy()\n",
    "        while tensor_A.canGrow(A_dim_two, n, dim_span, micro_tile_size, micro_tile_loop_order, buffer_allocation, A_dim_one):\n",
    "            tensor_A.growDims(tensors, n, dim_span, constraints, micro_tile_size, micro_tile_loop_order, buffer_allocation, A_dim_one)\n",
    "            print(f\"Macro tile with shape: {constraints}\")\n",
    "            tensor_A.print_macro_tile(constraints, micro_tile_size)\n",
    "            print(\"\\n\")\n",
    "            \n",
    "            # grow along B_uncontracted_dim while contrained to A\n",
    "            constraints[B_uncontracted_dim] = None\n",
    "            dim_span[B_uncontracted_dim] = init_tile_size[B_uncontracted_dim].copy()\n",
    "            while tensor_B.canGrow(B_uncontracted_dim, n, dim_span, micro_tile_size, micro_tile_loop_order, buffer_allocation, contracted_dim):\n",
    "                tensor_B.growDims(tensors, n, dim_span, constraints, micro_tile_size, micro_tile_loop_order, buffer_allocation, contracted_dim)\n",
    "                print(f\"Macro tile with shape: {constraints}\")\n",
    "                tensor_B.print_macro_tile(constraints, micro_tile_size)\n",
    "                print(\"\\n\")\n",
    "                val = constraints[B_uncontracted_dim][1]\n",
    "                constraints[B_uncontracted_dim] = None\n",
    "                dim_span[B_uncontracted_dim] = [val, val]\n",
    "            val = constraints[A_dim_two][1]\n",
    "            constraints[A_dim_two] = None\n",
    "            dim_span[A_dim_two] = [val, val]\n",
    "\n",
    "        val = constraints[A_dim_one][1]\n",
    "        dim_span[A_dim_one] = [val, val]\n",
    "        constraints[A_dim_one] = None\n",
    "Tensor.DRT = DRT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a88a3a1-9881-407b-94a6-83a468c513bf",
   "metadata": {},
   "source": [
    "Let's test the DRT function!\\\n",
    "**Note**: The `buffer_size` variable below has the unit of bits. It specifies the amount of memory available. For our implementation of DRT, we assume that the two input tensors and the output tensor shares the available buffer space equally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d5125b-4606-4635-a2bc-5fa538e6a856",
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_tile_size = 4\n",
    "\n",
    "K = 15\n",
    "M = 15\n",
    "N = 15\n",
    "\n",
    "density = [0.8,0.8]\n",
    "seed = 0\n",
    "\n",
    "A_KM = Tensor.fromRandom(rank_ids=[\"K\", \"M\"], shape=[K, M], seed=seed, density=density, name=\"A\")\n",
    "B_KN = Tensor.fromRandom(rank_ids=[\"K\", \"N\"], shape=[K, N], seed=seed + 1, density=density, name=\"B\")\n",
    "A_K1M1K0M0 = A_KM.generateMicroTiles(micro_tile_size)\n",
    "B_K1N1K0N0 = B_KN.generateMicroTiles(micro_tile_size)\n",
    "tensors = [A_K1M1K0M0, B_K1N1K0N0]\n",
    "loop_order = [\"N.1\", \"M.1\", \"K.1\"]\n",
    "micro_tile_loop_order = [\"K.0\", \"M.0\", \"N.0\"]\n",
    "init_tile_size = {\"K.1\": [0,0], \"M.1\": [0,0], \"N.1\": [0,2]}\n",
    "buffer_size = 9000\n",
    "\n",
    "print(\"Tensor A\")\n",
    "displayTensor(A_KM)\n",
    "print(\"\\nTensor B\")\n",
    "displayTensor(B_KN)\n",
    "\n",
    "print(\"\\nTensor A pre-processed into micro tiles\")\n",
    "displayTensor(A_K1M1K0M0)\n",
    "print(\"\\nTensor B pre-processed into micro tiles\")\n",
    "displayTensor(B_K1N1K0N0)\n",
    "\n",
    "print(\"\\nTensor A micro tile footprint\")\n",
    "displayTensor(A_K1M1K0M0.getMicroTileFootprint_LoopOrder(micro_tile_size, micro_tile_loop_order))\n",
    "print(\"\\nTensor B micro tile footprint\")\n",
    "displayTensor(B_K1N1K0N0.getMicroTileFootprint_LoopOrder(micro_tile_size, micro_tile_loop_order))\n",
    "print(\"\\n\")\n",
    "\n",
    "Tensor.DRT(tensors, loop_order, init_tile_size, micro_tile_size, micro_tile_loop_order, buffer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a49341c-e505-47df-9cbf-65c8e99c6522",
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_tile_size = 4\n",
    "\n",
    "K = 10\n",
    "M = 10\n",
    "N = 10\n",
    "\n",
    "density = [0.8,0.8]\n",
    "seed = 0\n",
    "\n",
    "A_KM = Tensor.fromRandom(rank_ids=[\"K\", \"M\"], shape=[K, M], seed=seed, density=density, name=\"A\")\n",
    "B_KN = Tensor.fromRandom(rank_ids=[\"K\", \"N\"], shape=[K, N], seed=seed + 1, density=density, name=\"B\")\n",
    "A_K1M1K0M0 = A_KM.generateMicroTiles(micro_tile_size)\n",
    "B_K1N1K0N0 = B_KN.generateMicroTiles(micro_tile_size)\n",
    "tensors = [A_K1M1K0M0, B_K1N1K0N0]\n",
    "loop_order = [\"K.1\", \"M.1\", \"N.1\"]\n",
    "micro_tile_loop_order = [\"K.0\", \"M.0\", \"N.0\"]\n",
    "init_tile_size = {\"K.1\": [0,0], \"M.1\": [0,3], \"N.1\": [0,0]}\n",
    "buffer_size = 9000\n",
    "\n",
    "print(\"Tensor A\")\n",
    "displayTensor(A_KM)\n",
    "print(\"\\nTensor B\")\n",
    "displayTensor(B_KN)\n",
    "\n",
    "print(\"\\nTensor A pre-processed into micro tiles\")\n",
    "displayTensor(A_K1M1K0M0)\n",
    "print(\"\\nTensor B pre-processed into micro tiles\")\n",
    "displayTensor(B_K1N1K0N0)\n",
    "\n",
    "print(\"\\nTensor A micro tile footprint\")\n",
    "displayTensor(A_K1M1K0M0.getMicroTileFootprint_LoopOrder(micro_tile_size, micro_tile_loop_order))\n",
    "print(\"\\nTensor B micro tile footprint\")\n",
    "displayTensor(B_K1N1K0N0.getMicroTileFootprint_LoopOrder(micro_tile_size, micro_tile_loop_order))\n",
    "print(\"\\n\")\n",
    "\n",
    "Tensor.DRT(tensors, loop_order, init_tile_size, micro_tile_size, micro_tile_loop_order, buffer_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2533beb7-40fd-4854-921d-934a2e525a7f",
   "metadata": {},
   "source": [
    "## Matrix Multiplication\n",
    "\n",
    "After DRT returns all tiled tensors. We will still need to implement functions that will perform matrix multiplication."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9e09bb-5b39-43ce-8e2f-9b6bd217a351",
   "metadata": {},
   "source": [
    "Since the `DRT` function above prints out tiled tensors rather than returning them, we will need to modify the function. The `getDRT` function will now return two sets of lists containing tiles of the two input matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3308c5-dd1e-4486-903f-8b6c0771f594",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDRT(tensors, loop_order, init_tile_size, micro_tile_size, micro_tile_loop_order, buffer_size):\n",
    "    \"\"\" Gets the next macro tile\n",
    "    Parameters\n",
    "    ----------\n",
    "    tensors: list of tensors\n",
    "        Includes all tensors processed\n",
    "    loop_order: list of strings\n",
    "        Specifies the loop order of the kernel\n",
    "    init_tile_size: dictionary\n",
    "        Gives the initial macro tile size\n",
    "    micro_tile_size: integer\n",
    "        Specifies the tile size of a micro tile\n",
    "    micro_tile_loop_order: list of strings\n",
    "        Specifies the loop order of which a micro tile is processed\n",
    "    buffer_size: integer\n",
    "        The size of the buffer DRT is building a macro tile for in bits\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    res_A: list of tensors\n",
    "        List contains macro tiles of A\n",
    "    res_B: list of tensors\n",
    "        List contains macro tiles of B\n",
    "    \"\"\"\n",
    "    \n",
    "    all_dims = []\n",
    "\n",
    "    # Prepare all tensors for processing\n",
    "    for tensor in tensors:\n",
    "        tensor = tensor.swizzleRanks(rank_ids = Tensor.orderDims(tensors, tensor.getRankIds()[0:2]) + Tensor.orderDims(tensors, tensor.getRankIds()[2:]))\n",
    "        all_dims.append(set(tensor.dims()))\n",
    "\n",
    "    # Find all dimensions involved\n",
    "    all_dims = all_dims[0].union(all_dims[1])\n",
    "\n",
    "    # Set up constrains and dim_span. Both are needed for function calls later\n",
    "    constraints = {dim: None for dim in all_dims}\n",
    "    dim_span =  {dim: init_tile_size[dim].copy() for dim in all_dims}\n",
    "\n",
    "    n = 1\n",
    "    tensors = Tensor.sortByStationarity(tensors, loop_order)\n",
    "    tensor_A = tensors[0]\n",
    "    tensor_B = tensors[1]\n",
    "    buffer_allocation = buffer_size // 3\n",
    "    \n",
    "    contracted_dim = Tensor.orderDims(tensors, tensor_A.getRankIds()[0:2])[0]\n",
    "    A_uncontracted_dim = Tensor.orderDims(tensors, tensor_A.getRankIds()[0:2])[1]\n",
    "    B_uncontracted_dim = Tensor.orderDims(tensors, tensor_B.getRankIds()[0:2])[1]\n",
    "\n",
    "    A_constrain_contracted_dim = True\n",
    "    if loop_order.index(contracted_dim) > loop_order.index(A_uncontracted_dim):\n",
    "        A_constrain_contracted_dim = False\n",
    "    B_constrain_contracted_dim = True\n",
    "    if loop_order.index(contracted_dim) > loop_order.index(B_uncontracted_dim):\n",
    "        B_constrain_contracted_dim = False\n",
    "\n",
    "    if A_constrain_contracted_dim:\n",
    "        A_dim_one = contracted_dim\n",
    "        A_dim_two = A_uncontracted_dim\n",
    "    else:\n",
    "        A_dim_one = A_uncontracted_dim\n",
    "        A_dim_two = contracted_dim\n",
    "\n",
    "    res_A = []\n",
    "    res_B = []\n",
    "    \n",
    "    # grow along contracted_dim\n",
    "    dim_span[A_dim_one] = [0, 0]\n",
    "    while tensor_A.canGrow(A_dim_one, n, dim_span, micro_tile_size, micro_tile_loop_order, buffer_allocation, A_dim_one):\n",
    "        dim_span[A_dim_one][1] += init_tile_size[A_dim_one][1]\n",
    "        # grow along A_dim_two\n",
    "        constraints[A_dim_two] = None\n",
    "        dim_span[A_dim_two] = init_tile_size[A_dim_two].copy()\n",
    "        while tensor_A.canGrow(A_dim_two, n, dim_span, micro_tile_size, micro_tile_loop_order, buffer_allocation, A_dim_one):\n",
    "            tensor_A.growDims(tensors, n, dim_span, constraints, micro_tile_size, micro_tile_loop_order, buffer_allocation, A_dim_one)\n",
    "            res_A.append(tensor_A.return_macro_tile(constraints, micro_tile_size))\n",
    "            res_B.append([])\n",
    "            \n",
    "            # grow along B_uncontracted_dim while contrained to A\n",
    "            constraints[B_uncontracted_dim] = None\n",
    "            dim_span[B_uncontracted_dim] = init_tile_size[B_uncontracted_dim].copy()\n",
    "            while tensor_B.canGrow(B_uncontracted_dim, n, dim_span, micro_tile_size, micro_tile_loop_order, buffer_allocation, contracted_dim):\n",
    "                tensor_B.growDims(tensors, n, dim_span, constraints, micro_tile_size, micro_tile_loop_order, buffer_allocation, contracted_dim)\n",
    "                res_B[-1].append(tensor_B.return_macro_tile(constraints, micro_tile_size))\n",
    "                val = constraints[B_uncontracted_dim][1]\n",
    "                constraints[B_uncontracted_dim] = None\n",
    "                dim_span[B_uncontracted_dim] = [val, val]\n",
    "            val = constraints[A_dim_two][1]\n",
    "            constraints[A_dim_two] = None\n",
    "            dim_span[A_dim_two] = [val, val]\n",
    "\n",
    "        val = constraints[A_dim_one][1]\n",
    "        dim_span[A_dim_one] = [val, val]\n",
    "        constraints[A_dim_one] = None\n",
    "    return res_A, res_B\n",
    "Tensor.getDRT = getDRT\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def return_macro_tile(self, constraints, micro_tile_size):\n",
    "    \"\"\"Returns a macro tile given a set of constraints\"\"\"\n",
    "    dims = self.getRankIds()\n",
    "    Z = Tensor(rank_ids=(self.getRankIds()))\n",
    "    difference = int(sqrt(micro_tile_size))\n",
    "    Z.setName(\"Macro tile \" + self.getName()[0] + \n",
    "              \"; Base point: \" + \n",
    "              str(constraints[self.getRankIds()[0]][0] * difference) + \",\" + \n",
    "              str(constraints[self.getRankIds()[1]][0] * difference))\n",
    "    z_i1 = Z.getRoot()\n",
    "    self_i = self.getRoot()\n",
    "    difference = int(sqrt(micro_tile_size))\n",
    "    for i, self_j in self_i:\n",
    "        if i >= constraints[self.getRankIds()[0]][1] * difference: # checks if we are selecting micro tiles out of scope\n",
    "            break\n",
    "        if i >= constraints[self.getRankIds()[0]][0] * difference:\n",
    "            for j, self_k in self_j:\n",
    "                if j >= constraints[self.getRankIds()[1]][1] * difference: # checks if we are selecting micro tiles out of scope\n",
    "                    break\n",
    "                if j >= constraints[self.getRankIds()[1]][0] * difference:\n",
    "                    z_k = z_i1.getPayloadRef(i, j)\n",
    "                    z_k <<= self_k\n",
    "    return Z\n",
    "Tensor.return_macro_tile = return_macro_tile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068d5ddb-8443-479c-94d0-02a4907089eb",
   "metadata": {},
   "source": [
    "Now we will implement matrix multiplication to handle the multiplication of micro tiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cef03f-740d-42bd-8209-954cc28944cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def microTile_innerProduct(A, B, base_point_A, base_point_B):\n",
    "    \"\"\"Handles micro tile multiplication using inner product dataflow\"\"\"\n",
    "    A = A.swizzleRanks(rank_ids=[\"M.0\", \"K.0\"])\n",
    "    B = B.swizzleRanks(rank_ids=[\"N.0\", \"K.0\"])\n",
    "    A_M0K0 = Tensor(rank_ids=[\"M.0\", \"K.0\"], name=\"A_M0K0\")\n",
    "    a_m0 = A.getRoot()\n",
    "    for m0, a_k0 in a_m0:\n",
    "        for k0, a_val in a_k0:\n",
    "            A_M0K0_ref = A_M0K0.getPayloadRef(m0 - base_point_A[\"M.0\"], k0 - base_point_A[\"K.0\"])\n",
    "            A_M0K0_ref += a_val\n",
    "    B_N0K0 = Tensor(rank_ids=[\"N.0\", \"K.0\"], name=\"B_N0K0\")\n",
    "    b_n0 = B.getRoot()\n",
    "    for n0, b_k0 in b_n0:\n",
    "        for k0, b_val in b_k0:\n",
    "            B_N0K0_ref = B_N0K0.getPayloadRef(n0 - base_point_B[\"N.0\"], k0 - base_point_B[\"K.0\"])\n",
    "            B_N0K0_ref += b_val\n",
    "\n",
    "    Z_MN = Tensor(rank_ids=[\"M\", \"N\"], name=\"Z\")\n",
    "    z_m = Z_MN.getRoot()\n",
    "    a_m0 = A_M0K0.getRoot()\n",
    "    b_n0 = B_N0K0.getRoot()\n",
    "    for m_pos, (m, (z_n, a_k0)) in enumerate(z_m << a_m0):\n",
    "        for n_pos, (n, (z_ref, b_k0)) in enumerate(z_n << b_n0):\n",
    "            for k_pos, (k, (a_val, b_val)) in enumerate(a_k0 & b_k0):\n",
    "                z_ref += a_val * b_val\n",
    "    return Z_MN\n",
    "\n",
    "def microTile_outerProduct(A, B, base_point_A, base_point_B):\n",
    "    \"\"\"Handles micro tile multiplication using outer product dataflow\"\"\"\n",
    "    A = A.swizzleRanks(rank_ids=[\"K.0\", \"M.0\"])\n",
    "    B = B.swizzleRanks(rank_ids=[\"K.0\", \"N.0\"])\n",
    "    A_K0M0 = Tensor(rank_ids=[\"K.0\", \"M.0\"], name=\"A_K0M0\")\n",
    "    a_k0 = A.getRoot()\n",
    "    for k0, a_m0 in a_k0:\n",
    "        for m0, a_val in a_m0:\n",
    "            A_K0M0_ref = A_K0M0.getPayloadRef(k0 - base_point_A[\"K.0\"], m0 - base_point_A[\"M.0\"])\n",
    "            A_K0M0_ref += a_val\n",
    "    B_K0N0 = Tensor(rank_ids=[\"K.0\", \"N.0\"], name=\"B_K0N0\")\n",
    "    b_k0 = B.getRoot()\n",
    "    for k0, b_n0 in b_k0:\n",
    "        for n0, b_val in b_n0:\n",
    "            B_K0N0_ref = B_K0N0.getPayloadRef(k0 - base_point_B[\"K.0\"], n0 - base_point_B[\"N.0\"])\n",
    "            B_K0N0_ref += b_val\n",
    "    \n",
    "    Z_MN = Tensor(rank_ids=[\"M\", \"N\"], name=\"Z\")\n",
    "    z_m = Z_MN.getRoot()\n",
    "    a_k0 = A_K0M0.getRoot()\n",
    "    b_k0 = B_K0N0.getRoot()\n",
    "    for k_pos, (k, (a_m0, b_n0)) in enumerate(a_k0 & b_k0):\n",
    "        for m_pos, (m, (z_n, a_val)) in enumerate(z_m << a_m0):\n",
    "            for n_pos, (n, (z_ref, b_val)) in enumerate(z_n << b_n0):\n",
    "                z_ref += a_val * b_val\n",
    "    return Z_MN\n",
    "\n",
    "def microTile_Gustavson(A, B, base_point_A, base_point_B):\n",
    "    \"\"\"Handles micro tile multiplication using Gustavson's dataflow\"\"\"\n",
    "    A = A.swizzleRanks(rank_ids=[\"M.0\", \"K.0\"])\n",
    "    B = B.swizzleRanks(rank_ids=[\"K.0\", \"N.0\"])\n",
    "    A_M0K0 = Tensor(rank_ids=[\"M.0\", \"K.0\"], name=\"A_M0K0\")\n",
    "    a_m0 = A.getRoot()\n",
    "    for m0, a_k0 in a_m0:\n",
    "        for k0, a_val in a_k0:\n",
    "            A_M0K0_ref = A_M0K0.getPayloadRef(m0 - base_point_A[\"M.0\"], k0 - base_point_A[\"K.0\"])\n",
    "            A_M0K0_ref += a_val\n",
    "    B_K0N0 = Tensor(rank_ids=[\"K.0\", \"N.0\"], name=\"B_K0N0\")\n",
    "    b_k0 = B.getRoot()\n",
    "    for k0, b_n0 in b_k0:\n",
    "        for n0, b_val in b_n0:\n",
    "            B_K0N0_ref = B_K0N0.getPayloadRef(k0 - base_point_B[\"K.0\"], n0 - base_point_B[\"N.0\"])\n",
    "            B_K0N0_ref += b_val\n",
    "            \n",
    "    Z_MN = Tensor(rank_ids=[\"M\", \"N\"], name=\"Z\")\n",
    "    z_m = Z_MN.getRoot()\n",
    "    a_m0 = A_M0K0.getRoot()\n",
    "    b_k0 = B_K0N0.getRoot()\n",
    "    for m_pos, (m, (z_n, a_k0)) in enumerate(z_m << a_m0):\n",
    "        for k_pos, (k, (a_val, b_n0)) in enumerate(a_k0 & b_k0):\n",
    "            for n_pos, (n, (z_ref, b_val)) in enumerate(z_n << b_n0):\n",
    "                z_ref += a_val * b_val\n",
    "    return Z_MN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2d65f5-415d-4092-9b74-258c81a92a44",
   "metadata": {},
   "source": [
    "After multiplying micro tiles, we will also need a function that updates the final result of matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b47b92e-2f18-4a18-9a5a-93fdb051654a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateMatrix(finalResult, product, base_point):\n",
    "    \"\"\"Updates the FINALRESULT tensor given PRODUCT and BASE_POINT\"\"\"\n",
    "    product_m = product.getRoot()\n",
    "    for m, product_n in product_m:\n",
    "        for n, product_val in product_n:\n",
    "            finalResult_ref = finalResult.getPayloadRef(m + base_point[\"M.0\"], n + base_point[\"N.0\"])\n",
    "            finalResult_ref += product_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8b6e04-f453-4242-84a9-6a8f96cf4fce",
   "metadata": {},
   "source": [
    "Next, we will define functions that operates at the PE tile level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302b9e16-2c65-4241-9485-2c4495d85661",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PETile_outerProduct(finalResult, A, B, func):\n",
    "    A = A.swizzleRanks(rank_ids=[\"K.1\", \"M.1\", \"K.0\", \"M.0\"])\n",
    "    B = B.swizzleRanks(rank_ids=[\"K.1\", \"N.1\", \"K.0\", \"N.0\"])\n",
    "    a_k1 = A.getRoot()\n",
    "    b_k1 = B.getRoot()\n",
    "    for k1_pos, (k1, (a_m1, b_n1)) in enumerate(a_k1 & b_k1):\n",
    "        for m1, a_k0 in a_m1:\n",
    "            in1 = Tensor.fromFiber(rank_ids=[\"K.0\", \"M.0\"], fiber=a_k0)\n",
    "            for n1, b_k0 in b_n1:\n",
    "                in2 = Tensor.fromFiber(rank_ids=[\"K.0\", \"N.0\"], fiber=b_k0)\n",
    "                product = func(in1, in2, {\"K.0\": k1_pos, \"M.0\": m1}, {\"K.0\": k1_pos, \"N.0\": n1})\n",
    "                updateMatrix(finalResult, product, {\"M.0\": m1, \"N.0\": n1})\n",
    "\n",
    "def PETile_Gustavson(finalResult, A, B, func):\n",
    "    A = A.swizzleRanks(rank_ids=[\"M.1\", \"K.1\", \"M.0\", \"K.0\"])\n",
    "    B = B.swizzleRanks(rank_ids=[\"K.1\", \"N.1\", \"K.0\", \"N.0\"])\n",
    "    a_m1 = A.getRoot()\n",
    "    b_k1 = B.getRoot()\n",
    "    for m1, a_k1 in a_m1:\n",
    "        for k1_pos, (k1, (a_m0, b_n1)) in enumerate(a_k1 & b_k1):\n",
    "            in1 = Tensor.fromFiber(rank_ids=[\"M.0\", \"K.0\"], fiber=a_m0)\n",
    "            for n1, b_k0 in b_n1:\n",
    "                in2 = Tensor.fromFiber(rank_ids=[\"K.0\", \"N.0\"], fiber=b_k0)\n",
    "                product = func(in1, in2, {\"K.0\": k1_pos, \"M.0\": m1}, {\"K.0\": k1_pos, \"N.0\": n1})\n",
    "                updateMatrix(finalResult, product, {\"M.0\": m1, \"N.0\": n1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5815d2-f649-425b-bfb7-a6db214fcd67",
   "metadata": {},
   "source": [
    "Similar to above, we need to define functions that operates at the global tile level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384088ef-8426-4d74-a869-064485bc1cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrixMultiplication(finalResult, A, B, PE_tile_func, micro_tile_func, loop_order, init_tile_size, micro_tile_size, micro_tile_loop_order, buffer_size):\n",
    "    tensors = [A, B]\n",
    "    tiles_A, tiles_B = Tensor.getDRT(tensors, loop_order, init_tile_size, micro_tile_size, micro_tile_loop_order, buffer_size)\n",
    "    for i in range(len(tiles_A)):\n",
    "        tile_A = tiles_A[i]\n",
    "        for tile_B in tiles_B[i]:\n",
    "            PE_tile_func(finalResult, tile_A, tile_B, micro_tile_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b0e594-f913-4ae9-8da4-9fd86796e209",
   "metadata": {},
   "source": [
    "Finally, we need to define a function that handles the tiling and distribution of global tiles (this is only used for ExTensor-OP-DRT)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98243048-8dab-4ba7-8e35-c326362ea2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrixMultiplication_ExTensor_OP_DRT(finalResult, A, B, PE_tile_func, micro_tile_func, loop_order_1, loop_order_2, init_tile_size_1, init_tile_size_2, micro_tile_size, micro_tile_loop_order, buffer_size_global, buffer_size_local):\n",
    "    tensors = [A, B]\n",
    "    tiles_A, tiles_B = Tensor.getDRT(tensors, loop_order_1, init_tile_size_1, micro_tile_size, micro_tile_loop_order, buffer_size_global)\n",
    "    for i in range(len(tiles_A)):\n",
    "        tile_A = tiles_A[i]\n",
    "        if tile_A.getRoot().countValues() == 0:\n",
    "            continue\n",
    "        for tile_B in tiles_B[i]:\n",
    "            if tile_B.getRoot().countValues() == 0:\n",
    "                continue\n",
    "            matrixMultiplication(finalResult, tile_B, tile_A, PE_tile_func, micro_tile_func, loop_order_2, init_tile_size_2, micro_tile_size, micro_tile_loop_order, buffer_size_local)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461b1012-5af7-450e-b11c-7c32b8280756",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "Initialize the input tensors. Tensor shapes and densities can be modified below.\n",
    "\n",
    "Note the following:\n",
    "1. In the paper, the authors specified in section 5.2.4 that \"input matrices are pre-processed into micro tiles of shape 32 × 32 for all workloads.\" However, for visualization and demonstration purposes, we will implement dynamic reflexive tiling based on micro tiles of shape 2 × 2 instead.\n",
    "2. Similarly, for visualization and demonstration purposes, the global buffer size and local buffer size are also reduced.\n",
    "3. The paper's focus is on the DRT algorithm and implementation. Strategies to determine the starting tile size and memory allocation for the input and output tensors are not the focus. Thus, for simplicity, our DRT implementation assumes that the input matrices A and B, as well as the output matrix C, each occupy one-third of the total memory.\n",
    "4. The fallback path for algorithm 1 mentioned in the DRT paper is not implemented. Thus, changing the input tensors, the initial tile size, or buffer sizes might lead to incorrect results as the tiling would be incomplete. This is especially true for ExTensor-OP-DRT because it runs through two rounds of DRT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f2d5f2-8a07-45d5-b92c-771e2df11b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_tile_size = 4\n",
    "\n",
    "K = 15\n",
    "M = 15\n",
    "N = 15\n",
    "\n",
    "density = [0.8,0.8]\n",
    "seed = 0\n",
    "\n",
    "# Initialize the tensors\n",
    "A_KM = Tensor.fromRandom(rank_ids=[\"K\", \"M\"], shape=[K, M], seed=seed, density=density, name=\"A\")\n",
    "B_KN = Tensor.fromRandom(rank_ids=[\"K\", \"N\"], shape=[K, N], seed=seed + 1, density=density, name=\"B\")\n",
    "\n",
    "# Preprocess A_KM and B_KN into tensors of micro tile granularity\n",
    "A_K1M1K0M0 = A_KM.generateMicroTiles(micro_tile_size)\n",
    "B_K1N1K0N0 = B_KN.generateMicroTiles(micro_tile_size)\n",
    "tensors = [A_K1M1K0M0, B_K1N1K0N0]\n",
    "buffer_size_allocation = 9000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f21285f-f51f-475f-bcaf-ceda9aba5768",
   "metadata": {},
   "source": [
    "Execute the following cell if you wish to visualize tensor `A_KM` and `B_KN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e37c98-a50d-422e-8f05-84d8f73afb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tensor A\")\n",
    "displayTensor(A_KM)\n",
    "print(\"\\nTensor B\")\n",
    "displayTensor(B_KN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133c85cd-644e-4c3d-9857-bbe276a49945",
   "metadata": {},
   "source": [
    "Execute the following cell if you wish to visualize tensor `A_K1M1K0M0` and `B_K1N1K0N0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115ef4fe-c6c9-4ea9-8e06-5d822ad066a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tensor A pre-processed into micro tiles\")\n",
    "displayTensor(A_K1M1K0M0)\n",
    "print(\"\\nTensor B pre-processed into micro tiles\")\n",
    "displayTensor(B_K1N1K0N0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2cf430-139a-4df7-a46d-8b0572e55ac5",
   "metadata": {},
   "source": [
    "## ExTensor-OP\n",
    "The authors of the paper proposed a modification to the original design of the [ExTensor accelerator](https://dl.acm.org/doi/10.1145/3352460.3358275). To remove a performance bottleneck, the dataflow between the global and the local buffer is changed from an inner product to an outer product dataflow. Note that local reductions of partial sums in the output tile is utlized in this case. Due to changes in the dataflow, a parallelized variant of ExTensor's intersection unit is also used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f57853f-3d47-4d09-a9e2-1e42ec3517e9",
   "metadata": {},
   "source": [
    "In the line below, we set the uniform partitioning of ExTensor-OP to generate uniform tiles of shape 2 × 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d823930c-d050-4b31-8a3a-99dbd1831e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "K1 = M1 = N1 = K0 = M0 = N0 = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3f1ac4-29ae-4762-947a-af71dfa332a0",
   "metadata": {},
   "source": [
    "To demonstrate DRT in the next three sections, the tensors that are initilized above are faily large. Thus, after compiling the yaml specification for ExTensor-OP, please comment out any line containing the keyword `canvas`. This will disable the video generator. Even after disabling the video generator, the results can still be verified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866d8bb4-780e-4ad7-9a78-5409fc72f58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml = \"\"\"\n",
    "einsum:\n",
    "    declaration:\n",
    "        A: [K, M]\n",
    "        B: [K, N]\n",
    "        Z: [M, N]\n",
    "    expressions:\n",
    "        - Z[m,n] = A[k,m] * B[k,n]\n",
    "mapping:\n",
    "    rank-order:\n",
    "        A: [K, M]\n",
    "        B: [K, N]\n",
    "        Z: [M, N]\n",
    "    partitioning:\n",
    "        Z:\n",
    "            K: [uniform_shape(K1), uniform_shape(K0)]\n",
    "            M: [uniform_shape(M1), uniform_shape(M0)]\n",
    "            N: [uniform_shape(N1), uniform_shape(N0)]\n",
    "    loop-order:\n",
    "        Z: [N2, K2, M2, K1, M1, N1, M0, N0, K0]\n",
    "    spacetime:\n",
    "        Z:\n",
    "            space: [N1]\n",
    "            time: [N2, K2, M2, K1, M1, M0, N0, K0]\n",
    "\"\"\"\n",
    "\n",
    "utils.compile(yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f071bed0-8e60-4fa2-b9ff-e51c9e6acc97",
   "metadata": {},
   "source": [
    "### Check Results\n",
    "\n",
    "Check that above code (generated or provided) computes the correct result.\n",
    "\n",
    "**Note**: Should be used after executing the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48888e38-7ec9-4e91-847f-b3f6fe1a18e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.check_matmul(A_KM, B_KN, Z_MN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c04216-132a-47c8-b236-e92a08ed314f",
   "metadata": {},
   "source": [
    "## ExTensor-OP-DRT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4412068-2431-443e-b149-db561dd9eb98",
   "metadata": {},
   "source": [
    "Since the ExTensor accelerator uses uniform shape partioning, it must take the worse case dense tensor into account when designing the partition. This would mean that when processing sparse tensors, ExTensor becomes memory inefficient. DRT solves this problem by building dynamic, non-uniform tiles during runtime to reduce DRAM traffic.\n",
    "\n",
    "**The YAML specification below is purely symbolic, running it will result in an error as DRT is not implemented in the current TeAAL compiler. Please run the code in the cell after the one below instead.**\n",
    "\n",
    "The notations below:\\\n",
    "(N12, K12, M12) specifies the global buffer tile\\\n",
    "(K11, M11, N11) specifies the PE tile\\\n",
    "(K10, M10, N10) specifies the micro tile\\\n",
    "(M0, N0, K0) specifies the element in a micro tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c374d07a-dc81-4363-9fe7-648506a28afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml = \"\"\"\n",
    "einsum:\n",
    "    declaration:\n",
    "        A: [K, M]\n",
    "        B: [K, N]\n",
    "        Z: [M, N]\n",
    "    expressions:\n",
    "        - Z[m,n] = A[k,m] ∗ B[k,n]\n",
    "mapping:\n",
    "    rank-order:\n",
    "        A: [K, M]\n",
    "        B: [K, N]\n",
    "        Z: [M, N]\n",
    "    partitioning:\n",
    "        Z:\n",
    "            K: [uniform_shape(32)]\n",
    "            M: [uniform_shape(32)]\n",
    "            N: [uniform_shape(32)]\n",
    "            (K1, M1, N1): [DRT(B, A), DRT(A, B)]\n",
    "    loop-order:\n",
    "        Z: [N12, K12, M12, K11, M11, N11, K10, M10, N10, M0, N0, K0]\n",
    "    spacetime:\n",
    "        Z:\n",
    "            space: [N11]\n",
    "            time: [N12, K12, M12, K11, M11, K10, M10, N10, M0, N0, K0]\n",
    "\"\"\"\n",
    "\n",
    "utils.compile(yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f772c414-e44e-463b-9224-b9c43382983d",
   "metadata": {},
   "source": [
    "Since DRT is not implemented in the TeAAL compiler, the HiFiber code is given below.\\\n",
    "**Note**: Because the fallback path in algorithm 1 of the DRT paper is not implemented, changing the parameters below may generate an incorrect result or an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d00a96c-6c32-45a4-aefd-b6c7a53f324e",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_buffer_size = 18000\n",
    "loop_order_1 = [\"N.1\", \"K.1\", \"M.1\"]\n",
    "local_buffer_size = 9000\n",
    "loop_order_2 = [\"K.1\", \"M.1\", \"N.1\"]\n",
    "micro_tile_loop_order = [\"M.0\", \"N.0\", \"K.0\"]\n",
    "init_tile_size_outer = {\"K.1\": [0,0], \"M.1\": [0,0], \"N.1\": [0,4]}\n",
    "init_tile_size_inner = {\"K.1\": [0,0], \"M.1\": [0,2], \"N.1\": [0,0]}\n",
    "Z_MN = Tensor(rank_ids=[\"M\", \"N\"], name = \"Z\")\n",
    "\n",
    "matrixMultiplication_ExTensor_OP_DRT(Z_MN, A_K1M1K0M0, B_K1N1K0N0, PETile_outerProduct, microTile_innerProduct, loop_order_1, loop_order_2, init_tile_size_outer, init_tile_size_inner, micro_tile_size, micro_tile_loop_order, global_buffer_size, local_buffer_size)\n",
    "displayTensor(Z_MN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08278bbb-0bf4-4eed-89ec-819097a7f52e",
   "metadata": {},
   "source": [
    "### Check Results\n",
    "\n",
    "Check that above code computes the correct result.\n",
    "\n",
    "**Note**: Should be used after executing the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ebb15c-10f8-4994-8026-a205a5c8d8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.check_matmul(A_KM, B_KN, Z_MN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117f0d16-93e0-4983-9e3c-47e18ca9b86b",
   "metadata": {},
   "source": [
    "## OuterSPACE-Like-DRT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef50777-e40c-484f-b50a-7cf2ce05260a",
   "metadata": {},
   "source": [
    "Similar to ExTensor-OP-DRT, DRT can also be applied to OuterSPACE-like accelerators, which uses an outer product dataflow.\n",
    "\n",
    "According to the paper: “The untiled baseline (original OuterSPACE proposal) distributes columns of A and rows of B, giving A and B perfect reuse, but Z poor reuse. Tiling of A and B reduces the working set size of output partial products, allowing them to be partially reduced on-chip, which reduces memory traffic. Additionally, tiling enables partial reuse across all three tensors.”\n",
    "\n",
    "The paper also mentioned that they “idealize these accelerators’ on-chip implementations, assuming they can reach their DRAM- bound performance.” Thus, the DRT process will only be applied to the global buffer layer only.\n",
    "\n",
    "**The YAML specification below is purely symbolic, running it will result in an error as DRT is not implemented in the current TeAAL compiler. Please run the code in the cell after the one below instead.**\n",
    "\n",
    "For the notations below:\\\n",
    "(K11, M11, N11) specifies the global buffer tile\\\n",
    "(K10, M10, N10) specifies the micro tile\\\n",
    "(K0, M0, N0) specifies the element in a micro tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9de289-45d8-48aa-8512-fd8919d76b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml = \"\"\"\n",
    "einsum:\n",
    "    declaration:\n",
    "        A: [K, M]\n",
    "        B: [K, N]\n",
    "        Z: [M, N]\n",
    "    expressions:\n",
    "        - Z[m,n] = A[k,m] ∗ B[k,n]\n",
    "mapping:\n",
    "    rank-order:\n",
    "        A: [K, M]\n",
    "        B: [K, N]\n",
    "        Z: [M, N]\n",
    "    partitioning:\n",
    "        Z:\n",
    "            K: [uniform_shape(32)]\n",
    "            M: [uniform_shape(32)]\n",
    "            N: [uniform_shape(32)]\n",
    "            (K1, M1, N1): [DRT(A, B)]\n",
    "    loop-order:\n",
    "        Z: [K11, M11, N11, K10, M10, N10, K0, M0, N0]\n",
    "    spacetime:\n",
    "        Z:\n",
    "            space: []\n",
    "            time: [K11, M11, N11, K10, M10, N10, K0, M0, N0]\n",
    "\"\"\"\n",
    "\n",
    "utils.compile(yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9a2dc6-8c94-487d-942d-987be770adc1",
   "metadata": {},
   "source": [
    "Since DRT is not implemented in the TeAAL compiler, the HiFiber code is given below.\\\n",
    "**Note**: Because the fallback path in algorithm 1 of the DRT paper is not implemented, changing the parameters below may generate an incorrect result or an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26043037-e65e-4536-b03b-c287ea172bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_tile_loop_order = [\"K.0\", \"M.0\", \"N.0\"]\n",
    "init_tile_size = {\"K.1\": [0,0], \"M.1\": [0,3], \"N.1\": [0,0]}\n",
    "loop_order = [\"K.1\", \"M.1\", \"N.1\"]\n",
    "Z_MN = Tensor(rank_ids=[\"M\", \"N\"], name = \"Z\")\n",
    "matrixMultiplication(Z_MN, A_K1M1K0M0, B_K1N1K0N0, PETile_outerProduct, microTile_outerProduct, loop_order, init_tile_size, micro_tile_size, micro_tile_loop_order, buffer_size_allocation)\n",
    "displayTensor(Z_MN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88194ce8-5d9a-4341-bfdc-5014e1a360ce",
   "metadata": {},
   "source": [
    "### Check Results\n",
    "\n",
    "Check that above code (generated or provided) computes the correct result.\n",
    "\n",
    "**Note**: Should be used after executing the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18400638-e6e6-4c4f-949e-b69799da8122",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.check_matmul(A_KM, B_KN, Z_MN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b66037b-79aa-47da-a763-3fd964038eae",
   "metadata": {},
   "source": [
    "## MatRaptor-Like-DRT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12dab00a-567f-4237-bb28-44cb45ce59d2",
   "metadata": {},
   "source": [
    "Finally, DRT can also be applied to MatRaptor-like accelerators, which uses the Gustavson's dataflow.\n",
    "\n",
    "Since the paper mentioned that they “idealize these accelerators’ on-chip implementations, assuming they can reach their DRAM- bound performance,” the DRT process will only be applied to the global buffer layer only.\n",
    "\n",
    "**The YAML specification below is purely symbolic, running it will result in an error as DRT is not implemented in the current TeAAL compiler. Please run the code in the cell after the one below instead.**\n",
    "\n",
    "For the notations below:\\\n",
    "(M11, K11, N11) specifies the global buffer tile\\\n",
    "(M10, K10, N10) specifies the micro tile\\\n",
    "(M0, K0, N0) specifies the element in a micro tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84af4c3-8e56-46c8-b155-8adaf9c6736a",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml = \"\"\"\n",
    "einsum:\n",
    "    declaration:\n",
    "        A: [K, M]\n",
    "        B: [K, N]\n",
    "        Z: [M, N]\n",
    "    expressions:\n",
    "        - Z[m,n] = A[k,m] ∗ B[k,n]\n",
    "    mapping:\n",
    "        rank-order:\n",
    "            A: [K, M]\n",
    "            B: [K, N]\n",
    "            Z: [M, N]\n",
    "    partitioning:\n",
    "        Z:\n",
    "            K: [uniform_shape(32)]\n",
    "            M: [uniform_shape(32)]\n",
    "            N: [uniform_shape(32)]\n",
    "            (K1, M1, N1): [DRT(A, B)]\n",
    "    loop-order:\n",
    "        Z: [M11, K11, N11, M10, K10, N10, M0, K0, N0]\n",
    "    spacetime:\n",
    "        Z:\n",
    "            space: []\n",
    "            time: [M11, K11, N11, M10, K10, N10, M0, K0, N0]\n",
    "\"\"\"\n",
    "\n",
    "utils.compile(yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61864c2b-03ed-47fb-9b8d-6d49e81d02cc",
   "metadata": {},
   "source": [
    "Since DRT is not implemented in the TeAAL compiler, the HiFiber code is given below.\\\n",
    "**Note**: Because the fallback path in algorithm 1 of the DRT paper is not implemented, changing the parameters below may generate an incorrect result or an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694a8adc-47aa-45e5-bfd7-531f0f2a2b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_tile_loop_order = [\"M.0\", \"K.0\", \"N.0\"]\n",
    "init_tile_size = {\"K.1\": [0,0], \"M.1\": [0,3], \"N.1\": [0,0]}\n",
    "loop_order = [\"M.1\", \"K.1\", \"N.1\"]\n",
    "finalResult = Tensor(rank_ids=[\"M\", \"N\"], name = \"Z\")\n",
    "matrixMultiplication(finalResult, A_K1M1K0M0, B_K1N1K0N0, PETile_Gustavson, microTile_Gustavson, loop_order, init_tile_size, micro_tile_size, micro_tile_loop_order, buffer_size_allocation)\n",
    "displayTensor(finalResult)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb10c67-0bab-4b37-b0ce-87a8665bbe47",
   "metadata": {},
   "source": [
    "### Check Results\n",
    "\n",
    "Check that above code (generated or provided) computes the correct result.\n",
    "\n",
    "**Note**: Should be used after executing the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9458e6fb-6669-46f4-a52d-1e45d1ff51a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.check_matmul(A_KM, B_KN, Z_MN)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
